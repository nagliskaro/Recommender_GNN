{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt at a GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(\"Data/Ratings.csv\")\n",
    "books = pd.read_csv(\"Data/Books.csv\", dtype={3: str})\n",
    "users = pd.read_csv(\"Data/Users.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 105283 unique users, and 340556 unique books in the ratings dataset.\n",
      "There are around 21.0% of books in the graph missing in the books data\n",
      "There are: 105283, who have rated at least one book\n"
     ]
    }
   ],
   "source": [
    "# We will only use users and books present in the ratings dataset \n",
    "lessen_user_ids = {userid: idx for idx, userid in enumerate(ratings['User-ID'].unique())} #renumber IDs to reduce inactive users\n",
    "ratings['New-User-ID'] = ratings['User-ID'].map(lessen_user_ids)\n",
    "user_ids = list(ratings['New-User-ID'].unique())\n",
    "num_users = len(set(user_ids))\n",
    "\n",
    "# Map book identifiers (ISBN) to a unique integer identifier for datatype compatibility of dgl\n",
    "isbn_to_id = {isbn: idx for idx, isbn in enumerate(ratings['ISBN'].unique())}\n",
    "ratings['Book-ID'] = ratings['ISBN'].map(isbn_to_id)\n",
    "book_ids = list(ratings['Book-ID'].unique())\n",
    "num_books = len(set(book_ids))\n",
    "\n",
    "print(f'There are {len(user_ids)} unique users, and {len(book_ids)} unique books in the ratings dataset.')\n",
    " \n",
    "# Remove users and books not included in the ratings dataset\n",
    "books['Book-ID'] = books['ISBN'].map(isbn_to_id)\n",
    "books_clean = books[books['Book-ID'].isin(book_ids)]\n",
    "books_clean_ids = books_clean['Book-ID'].unique()\n",
    "percent_books_missing = round((num_books-len(books_clean_ids))/num_books*100, 0)\n",
    "\n",
    "print(f'There are around {percent_books_missing}% of books in the graph missing in the books data')\n",
    "\n",
    "users['New-User-ID'] = users['User-ID'].map(lessen_user_ids)\n",
    "users_clean = users[users['New-User-ID'].isin(user_ids)]\n",
    "print(f\"There are: {len(users_clean['New-User-ID'])}, who have rated at least one book\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_with_book_titles = ratings.merge(books,on='ISBN')\n",
    "ratings_with_book_titles.drop(columns=[\"ISBN\",\"Image-URL-S\",\"Image-URL-M\"],axis=1,inplace=True)\n",
    "# Drop Age because tooo many missing values\n",
    "complete_df = ratings_with_book_titles.merge(users.drop(\"Age\", axis=1), on=\"User-ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['User-ID', 'Book-Rating', 'New-User-ID_x', 'Book-ID_x', 'Book-Title',\n",
      "       'Book-Author', 'Year-Of-Publication', 'Publisher', 'Image-URL-L',\n",
      "       'Book-ID_y', 'Location', 'New-User-ID_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "complete_df['Location'] = complete_df['Location'].str.split(',').str[-1].str.strip()\n",
    "print(complete_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "647294\n",
      "1031136\n"
     ]
    }
   ],
   "source": [
    "print((complete_df['Book-Rating'] == 0).sum())\n",
    "print(len(complete_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383842\n"
     ]
    }
   ],
   "source": [
    "df = complete_df.loc[complete_df['Book-Rating'] != 0]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print((df['Year-Of-Publication'] == 'DK Publishing Inc').sum())\n",
    "df = df[df['Year-Of-Publication'] != 'DK Publishing Inc']\n",
    "print((df['Year-Of-Publication'] == 'DK Publishing Inc').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>New-User-ID_x</th>\n",
       "      <th>Book-ID_x</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-L</th>\n",
       "      <th>Book-ID_y</th>\n",
       "      <th>Location</th>\n",
       "      <th>New-User-ID_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276726</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Rites of Passage</td>\n",
       "      <td>Judith Rae</td>\n",
       "      <td>2001</td>\n",
       "      <td>Heinle</td>\n",
       "      <td>http://images.amazon.com/images/P/0155061224.0...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>usa</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276729</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Help!: Level 1</td>\n",
       "      <td>Philip Prowse</td>\n",
       "      <td>1999</td>\n",
       "      <td>Cambridge University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/052165615X.0...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>croatia</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276729</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>The Amsterdam Connection : Level 4 (Cambridge ...</td>\n",
       "      <td>Sue Leather</td>\n",
       "      <td>2001</td>\n",
       "      <td>Cambridge University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0521795028.0...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>croatia</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>276744</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>A Painted House</td>\n",
       "      <td>JOHN GRISHAM</td>\n",
       "      <td>2001</td>\n",
       "      <td>Doubleday</td>\n",
       "      <td>http://images.amazon.com/images/P/038550120X.0...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>usa</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>276747</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>Little Altars Everywhere</td>\n",
       "      <td>Rebecca Wells</td>\n",
       "      <td>2003</td>\n",
       "      <td>HarperTorch</td>\n",
       "      <td>http://images.amazon.com/images/P/0060517794.0...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>usa</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User-ID  Book-Rating  New-User-ID_x  Book-ID_x  \\\n",
       "1    276726            5              1          1   \n",
       "3    276729            3              3          3   \n",
       "4    276729            6              3          4   \n",
       "6    276744            7              7          8   \n",
       "13   276747            9             10         16   \n",
       "\n",
       "                                           Book-Title    Book-Author  \\\n",
       "1                                    Rites of Passage     Judith Rae   \n",
       "3                                      Help!: Level 1  Philip Prowse   \n",
       "4   The Amsterdam Connection : Level 4 (Cambridge ...    Sue Leather   \n",
       "6                                     A Painted House   JOHN GRISHAM   \n",
       "13                           Little Altars Everywhere  Rebecca Wells   \n",
       "\n",
       "   Year-Of-Publication                   Publisher  \\\n",
       "1                 2001                      Heinle   \n",
       "3                 1999  Cambridge University Press   \n",
       "4                 2001  Cambridge University Press   \n",
       "6                 2001                   Doubleday   \n",
       "13                2003                 HarperTorch   \n",
       "\n",
       "                                          Image-URL-L  Book-ID_y Location  \\\n",
       "1   http://images.amazon.com/images/P/0155061224.0...        1.0      usa   \n",
       "3   http://images.amazon.com/images/P/052165615X.0...        3.0  croatia   \n",
       "4   http://images.amazon.com/images/P/0521795028.0...        4.0  croatia   \n",
       "6   http://images.amazon.com/images/P/038550120X.0...        8.0      usa   \n",
       "13  http://images.amazon.com/images/P/0060517794.0...       16.0      usa   \n",
       "\n",
       "    New-User-ID_y  \n",
       "1             1.0  \n",
       "3             3.0  \n",
       "4             3.0  \n",
       "6             7.0  \n",
       "13           10.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(383841, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68091\n",
      "135566\n"
     ]
    }
   ],
   "source": [
    "print(len(df['User-ID'].unique()))\n",
    "print(len(df['Book-Title'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start with graph structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maretreinders/Documents/3rd year AUC/TM/GNN/env_GNN/lib/python3.11/site-packages/threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = HeteroData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique users\n",
    "unique_users = df[['User-ID', 'Location']].drop_duplicates()\n",
    "\n",
    "# Take care of the User-IDs\n",
    "user_id_encoder = LabelEncoder()\n",
    "df['encoded-user-ID'] = user_id_encoder.fit_transform(df['User-ID'].astype(str))    # Do so otherwise it is going to create a problem with tensor indexing later\n",
    "unique_users['User-ID'] = df['encoded-user-ID']\n",
    "\n",
    "# Encode the Location feature\n",
    "location_encoder = LabelEncoder()\n",
    "unique_users['Location'] = location_encoder.fit_transform(unique_users['Location'])\n",
    "\n",
    "# Get tensor\n",
    "user_features_tensor = torch.tensor(unique_users[['User-ID', 'Location']].values, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['users'].x = user_features_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([68091, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['users'].x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Book nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a composite key that uniquely identifies each book\n",
    "df['Book-Key'] = df['Book-Title'] + '|' + df['Book-Author'] + '|' + df['Publisher'] + '|' + df['Year-Of-Publication'].astype(str)\n",
    "\n",
    "# Now, get unique books using the new composite key\n",
    "unique_books = df[['Book-Key', 'Book-Title', 'Book-Author', 'Publisher', 'Year-Of-Publication']].drop_duplicates()\n",
    "\n",
    "# Encode categorical features\n",
    "book_key_encoder = LabelEncoder()\n",
    "unique_books['Book-Key'] = book_key_encoder.fit_transform(unique_books['Book-Key'])\n",
    "\n",
    "title_encoder = LabelEncoder()\n",
    "author_encoder = LabelEncoder()\n",
    "publisher_encoder = LabelEncoder()\n",
    "\n",
    "unique_books['Book-Title'] = title_encoder.fit_transform(unique_books['Book-Title'])\n",
    "unique_books['Book-Author'] = author_encoder.fit_transform(unique_books['Book-Author'])\n",
    "unique_books['Publisher'] = publisher_encoder.fit_transform(unique_books['Publisher'])\n",
    "\n",
    "# Normalize year of publication\n",
    "unique_books['Year-Of-Publication'] = unique_books['Year-Of-Publication'].astype(int)\n",
    "min_year = unique_books['Year-Of-Publication'].min()\n",
    "max_year = unique_books['Year-Of-Publication'].max()\n",
    "unique_books['Year-Of-Publication'] = (unique_books['Year-Of-Publication'] - min_year) / (max_year - min_year)\n",
    "\n",
    "# Convert to tensor\n",
    "book_features_tensor = torch.tensor(unique_books[['Book-Title', 'Book-Author', 'Publisher', 'Year-Of-Publication']].values, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['books'].x = book_features_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([149243, 4])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['books'].x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_indices = df['encoded-user-ID'].to_numpy()\n",
    "book_indices = book_key_encoder.transform(df['Book-Key'])\n",
    "\n",
    "# Create tensors for user indices, book indices, and ratings\n",
    "user_indices_tensor = torch.tensor(user_indices, dtype=torch.long)\n",
    "book_indices_tensor = torch.tensor(book_indices, dtype=torch.long)\n",
    "ratings_tensor = torch.tensor(df['Book-Rating'].values, dtype=torch.float)\n",
    "\n",
    "# Adding edge data (edges from 'user' to 'book' with a relationship 'rated')\n",
    "data['users', 'rated', 'books'].edge_index = torch.stack([user_indices_tensor, book_indices_tensor], dim=0)\n",
    "data['users', 'rated', 'books'].edge_attr = ratings_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "383841"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['users', 'rated', 'books'].num_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  users={ x=[68091, 2] },\n",
      "  books={ x=[149243, 4] },\n",
      "  (users, rated, books)={\n",
      "    edge_index=[2, 383841],\n",
      "    edge_attr=[383841],\n",
      "  }\n",
      ")\n",
      "{('users', 'rated', 'books'): tensor([[ 47760,  47761,  47761,  ...,  47756,  47757,  47759],\n",
      "        [ 92341,  50886, 107531,  ...,  45852, 128517,  43549]])}\n",
      "tensor([ 5.,  3.,  6.,  ...,  9., 10., 10.])\n"
     ]
    }
   ],
   "source": [
    "print(data)\n",
    "print(data.edge_index_dict)\n",
    "print(data['users', 'rated', 'books'].edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User indices range: 0 68090\n",
      "Book indices range: 0 149239\n"
     ]
    }
   ],
   "source": [
    "edge_index = data['users', 'rated', 'books'].edge_index\n",
    "\n",
    "print(\"User indices range:\", edge_index[0].min().item(), edge_index[0].max().item())\n",
    "print(\"Book indices range:\", edge_index[1].min().item(), edge_index[1].max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(data.x_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import HeteroConv, SAGEConv, Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = T.ToUndirected(merge=True)(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  users={ x=[68091, 2] },\n",
      "  books={ x=[149243, 4] },\n",
      "  (users, rated, books)={\n",
      "    edge_index=[2, 383841],\n",
      "    edge_attr=[383841],\n",
      "  }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maretreinders/Documents/3rd year AUC/TM/GNN/env_GNN/lib/python3.11/site-packages/torch_geometric/nn/conv/hetero_conv.py:76: UserWarning: There exist node types ({'user'}) whose representations do not get updated during message passing as they do not occur as destination type in any edge type. This may lead to unexpected behavior.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# class LinkPredictionModel(torch.nn.Module):\n",
    "#     def __init__(self, hidden_channels):\n",
    "#         super().__init__()\n",
    "#         self.user_conv = SAGEConv(-1, hidden_channels)  # Automatically infer input channels\n",
    "#         self.book_conv = SAGEConv(-1, hidden_channels)\n",
    "#         self.fc = Linear(2 * hidden_channels, 1)\n",
    "\n",
    "#     def forward(self, x_dict, edge_index_dict):\n",
    "#         # Update node features\n",
    "#         x_dict['users'] = F.relu(self.user_conv(x_dict['users'], edge_index_dict[('users', 'rated', 'books')]))\n",
    "#         x_dict['books'] = F.relu(self.book_conv(x_dict['books'], edge_index_dict[('books', 'rev_rated', 'users')]))\n",
    "\n",
    "#         # Concatenate user and book features for each edge\n",
    "#         user_features = x_dict['users'][edge_index_dict[('users', 'rated', 'books')][0]]\n",
    "#         book_features = x_dict['books'][edge_index_dict[('users', 'rated', 'books')][1]]\n",
    "#         edge_features = torch.cat([user_features, book_features], dim=1)\n",
    "\n",
    "#         # Predict the existence of a link\n",
    "#         return torch.sigmoid(self.fc(edge_features))\n",
    "\n",
    "# model = LinkPredictionModel(hidden_channels=32)\n",
    "\n",
    "class HeteroGNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels, num_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv = HeteroConv({\n",
    "                ('user', 'rates', 'book'): SAGEConv((-1, -1), hidden_channels),\n",
    "            }, aggr='sum')\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        self.lin = Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        for conv in self.convs:\n",
    "            x_dict = conv(x_dict, edge_index_dict)\n",
    "            x_dict = {key: F.relu(x) for key, x in x_dict.items()}\n",
    "        return self.lin(x_dict['user'])\n",
    "\n",
    "model = HeteroGNN(hidden_channels=64, out_channels=1, num_layers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.nn import BCELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'data' is your HeteroData object and it has a 'book' key\n",
    "num_books = data['books'].x.size(0)  # Total number of books\n",
    "\n",
    "# Creating a mask with 80% of the data for training\n",
    "train_mask = torch.rand(num_books) < 0.8\n",
    "\n",
    "# Assigning the mask to your data object\n",
    "data['books'].train_mask = train_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=0.01)\n",
    "# criterion = BCELoss()\n",
    "\n",
    "# def train(model, data, optimizer, criterion):\n",
    "#     model.train()\n",
    "#     optimizer.zero_grad()\n",
    "\n",
    "#     predictions = model(data.x_dict, data.edge_index_dict)\n",
    "#     actuals = (data['users', 'rated', 'books'].edge_attr > 7).float()  # Assuming 7+ is positive\n",
    "\n",
    "#     loss = criterion(predictions.squeeze(), actuals)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     return loss.item()\n",
    "\n",
    "# # Run the training loop\n",
    "# for epoch in range(1, 11):\n",
    "#     loss = train(model, data, optimizer, criterion)\n",
    "#     print(f'Epoch {epoch}, Loss: {loss:.4f}')\n",
    "\n",
    "def train(batch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(batch.x_dict, batch.edge_index_dict)\n",
    "    mask = batch['book'].train_mask  # Assuming you have a train mask for books\n",
    "    loss = F.cross_entropy(out[mask], batch['book'].y[mask])  # Adjust according to your label setup\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maretreinders/Documents/3rd year AUC/TM/GNN/env_GNN/lib/python3.11/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set 'set()'. Please explicitly set 'num_nodes' as an attribute of 'data[book]' to suppress this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'EdgeStorage' object has no attribute 'edge_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m transform \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mToUndirected()  \u001b[38;5;66;03m# Make sure edges are bidirectional.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m data \u001b[38;5;241m=\u001b[39m transform(data)  \u001b[38;5;66;03m# Apply transformation to your graph data.\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m \u001b[43mNeighborLoader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Sample 15 neighbors for each node and each edge type for 2 iterations:\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_neighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Use a batch size of 128 for sampling training nodes of type \"book\":\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbooks\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbooks\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Adjust this to your setup\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n",
      "File \u001b[0;32m~/Documents/3rd year AUC/TM/GNN/env_GNN/lib/python3.11/site-packages/torch_geometric/loader/neighbor_loader.py:229\u001b[0m, in \u001b[0;36mNeighborLoader.__init__\u001b[0;34m(self, data, num_neighbors, input_nodes, input_time, replace, subgraph_type, disjoint, temporal_strategy, time_attr, weight_attr, transform, transform_sampler_output, is_sorted, filter_per_worker, neighbor_sampler, directed, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mReceived conflicting \u001b[39m\u001b[39m'\u001b[39m\u001b[39minput_time\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtime_attr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m arguments: \u001b[39m\u001b[39m'\u001b[39m\u001b[39minput_time\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is set \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    226\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mwhile \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtime_attr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not set.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    228\u001b[0m \u001b[39mif\u001b[39;00m neighbor_sampler \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 229\u001b[0m     neighbor_sampler \u001b[39m=\u001b[39m NeighborSampler(\n\u001b[1;32m    230\u001b[0m         data,\n\u001b[1;32m    231\u001b[0m         num_neighbors\u001b[39m=\u001b[39;49mnum_neighbors,\n\u001b[1;32m    232\u001b[0m         replace\u001b[39m=\u001b[39;49mreplace,\n\u001b[1;32m    233\u001b[0m         subgraph_type\u001b[39m=\u001b[39;49msubgraph_type,\n\u001b[1;32m    234\u001b[0m         disjoint\u001b[39m=\u001b[39;49mdisjoint,\n\u001b[1;32m    235\u001b[0m         temporal_strategy\u001b[39m=\u001b[39;49mtemporal_strategy,\n\u001b[1;32m    236\u001b[0m         time_attr\u001b[39m=\u001b[39;49mtime_attr,\n\u001b[1;32m    237\u001b[0m         weight_attr\u001b[39m=\u001b[39;49mweight_attr,\n\u001b[1;32m    238\u001b[0m         is_sorted\u001b[39m=\u001b[39;49mis_sorted,\n\u001b[1;32m    239\u001b[0m         share_memory\u001b[39m=\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39mnum_workers\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m0\u001b[39;49m) \u001b[39m>\u001b[39;49m \u001b[39m0\u001b[39;49m,\n\u001b[1;32m    240\u001b[0m         directed\u001b[39m=\u001b[39;49mdirected,\n\u001b[1;32m    241\u001b[0m     )\n\u001b[1;32m    243\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[1;32m    244\u001b[0m     data\u001b[39m=\u001b[39mdata,\n\u001b[1;32m    245\u001b[0m     node_sampler\u001b[39m=\u001b[39mneighbor_sampler,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    252\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/3rd year AUC/TM/GNN/env_GNN/lib/python3.11/site-packages/torch_geometric/sampler/neighbor_sampler.py:139\u001b[0m, in \u001b[0;36mNeighborSampler.__init__\u001b[0;34m(self, data, num_neighbors, subgraph_type, replace, disjoint, temporal_strategy, time_attr, weight_attr, is_sorted, share_memory, directed)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_edge_type \u001b[39m=\u001b[39m {v: k \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_rel_type\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m    138\u001b[0m \u001b[39m# Convert the graph data into CSC format for sampling:\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m colptr_dict, row_dict, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mperm \u001b[39m=\u001b[39m to_hetero_csc(\n\u001b[1;32m    140\u001b[0m     data, device\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m'\u001b[39;49m, share_memory\u001b[39m=\u001b[39;49mshare_memory,\n\u001b[1;32m    141\u001b[0m     is_sorted\u001b[39m=\u001b[39;49mis_sorted, node_time_dict\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnode_time,\n\u001b[1;32m    142\u001b[0m     edge_time_dict\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49medge_time)\n\u001b[1;32m    144\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrow_dict \u001b[39m=\u001b[39m remap_keys(row_dict, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_rel_type)\n\u001b[1;32m    145\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolptr_dict \u001b[39m=\u001b[39m remap_keys(colptr_dict, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_rel_type)\n",
      "File \u001b[0;32m~/Documents/3rd year AUC/TM/GNN/env_GNN/lib/python3.11/site-packages/torch_geometric/sampler/utils.py:110\u001b[0m, in \u001b[0;36mto_hetero_csc\u001b[0;34m(data, device, share_memory, is_sorted, node_time_dict, edge_time_dict)\u001b[0m\n\u001b[1;32m    108\u001b[0m     src_node_time \u001b[39m=\u001b[39m (node_time_dict \u001b[39mor\u001b[39;00m {})\u001b[39m.\u001b[39mget(edge_type[\u001b[39m0\u001b[39m], \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    109\u001b[0m     edge_time \u001b[39m=\u001b[39m (edge_time_dict \u001b[39mor\u001b[39;00m {})\u001b[39m.\u001b[39mget(edge_type, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m--> 110\u001b[0m     out \u001b[39m=\u001b[39m to_csc(store, device, share_memory, is_sorted, src_node_time,\n\u001b[1;32m    111\u001b[0m                  edge_time)\n\u001b[1;32m    112\u001b[0m     colptr_dict[edge_type], row_dict[edge_type], perm_dict[edge_type] \u001b[39m=\u001b[39m out\n\u001b[1;32m    114\u001b[0m \u001b[39mreturn\u001b[39;00m colptr_dict, row_dict, perm_dict\n",
      "File \u001b[0;32m~/Documents/3rd year AUC/TM/GNN/env_GNN/lib/python3.11/site-packages/torch_geometric/sampler/utils.py:70\u001b[0m, in \u001b[0;36mto_csc\u001b[0;34m(data, device, share_memory, is_sorted, src_node_time, edge_time)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     colptr, row, _ \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39madj_t\u001b[39m.\u001b[39mcsr()\n\u001b[0;32m---> 70\u001b[0m \u001b[39melif\u001b[39;00m data\u001b[39m.\u001b[39;49medge_index \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     71\u001b[0m     row, col \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39medge_index\n\u001b[1;32m     72\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_sorted:\n",
      "File \u001b[0;32m~/Documents/3rd year AUC/TM/GNN/env_GNN/lib/python3.11/site-packages/torch_geometric/data/storage.py:96\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[key]\n\u001b[1;32m     95\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m     97\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EdgeStorage' object has no attribute 'edge_index'"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import NeighborLoader\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "transform = T.ToUndirected()  # Make sure edges are bidirectional.\n",
    "\n",
    "data = transform(data)  # Apply transformation to your graph data.\n",
    "\n",
    "train_loader = NeighborLoader(\n",
    "    data,\n",
    "    # Sample 15 neighbors for each node and each edge type for 2 iterations:\n",
    "    num_neighbors=[15] * 2,\n",
    "    # Use a batch size of 128 for sampling training nodes of type \"book\":\n",
    "    batch_size=128,\n",
    "    input_nodes=('books', data['books'].train_mask),  # Adjust this to your setup\n",
    ")\n",
    "\n",
    "# Example usage\n",
    "for batch in train_loader:\n",
    "    loss = train(batch)\n",
    "    print(f'Loss: {loss:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('env_GNN': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f6377febe87314814c7b7161cea679ad38a9298f17e15a391a898e937fe96e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
