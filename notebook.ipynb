{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Book Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dgl in /Users/linkamitome/anaconda3/lib/python3.11/site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /Users/linkamitome/anaconda3/lib/python3.11/site-packages (from dgl) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /Users/linkamitome/anaconda3/lib/python3.11/site-packages (from dgl) (1.10.1)\n",
      "Requirement already satisfied: networkx>=2.1 in /Users/linkamitome/anaconda3/lib/python3.11/site-packages (from dgl) (2.8.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/linkamitome/anaconda3/lib/python3.11/site-packages (from dgl) (2.29.0)\n",
      "Requirement already satisfied: tqdm in /Users/linkamitome/anaconda3/lib/python3.11/site-packages (from dgl) (4.65.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /Users/linkamitome/anaconda3/lib/python3.11/site-packages (from dgl) (5.9.0)\n",
      "Requirement already satisfied: torchdata>=0.5.0 in /Users/linkamitome/anaconda3/lib/python3.11/site-packages (from dgl) (0.7.1)\n",
      "Requirement already satisfied: pandas in /Users/linkamitome/anaconda3/lib/python3.11/site-packages (from dgl) (2.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/linkamitome/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->dgl) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/linkamitome/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->dgl) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/linkamitome/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->dgl) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/linkamitome/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->dgl) (2023.11.17)\n",
      "Requirement already satisfied: torch>=2 in /Users/linkamitome/anaconda3/lib/python3.11/site-packages (from torchdata>=0.5.0->dgl) (2.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/linkamitome/anaconda3/lib/python3.11/site-packages (from pandas->dgl) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/linkamitome/anaconda3/lib/python3.11/site-packages (from pandas->dgl) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/linkamitome/anaconda3/lib/python3.11/site-packages (from pandas->dgl) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/linkamitome/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->dgl) (1.16.0)\n",
      "Requirement already satisfied: filelock in /Users/linkamitome/anaconda3/lib/python3.11/site-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/linkamitome/anaconda3/lib/python3.11/site-packages (from torch>=2->torchdata>=0.5.0->dgl) (4.10.0)\n",
      "Requirement already satisfied: sympy in /Users/linkamitome/anaconda3/lib/python3.11/site-packages (from torch>=2->torchdata>=0.5.0->dgl) (1.11.1)\n",
      "Requirement already satisfied: jinja2 in /Users/linkamitome/anaconda3/lib/python3.11/site-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/linkamitome/anaconda3/lib/python3.11/site-packages (from torch>=2->torchdata>=0.5.0->dgl) (2023.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/linkamitome/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=2->torchdata>=0.5.0->dgl) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/linkamitome/anaconda3/lib/python3.11/site-packages (from sympy->torch>=2->torchdata>=0.5.0->dgl) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install dgl\n",
    "import dgl\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings Data Shape: (1149780, 3) \n",
      "\n",
      "User-ID         int64\n",
      "ISBN           object\n",
      "Book-Rating     int64\n",
      "dtype: object\n",
      "\n",
      "   User-ID        ISBN  Book-Rating\n",
      "0   276725  034545104X            0\n",
      "1   276726  0155061224            5\n",
      "2   276727  0446520802            0\n",
      "3   276729  052165615X            3\n",
      "4   276729  0521795028            6\n"
     ]
    }
   ],
   "source": [
    "ratings = pd.read_csv(\"Data/Ratings.csv\")\n",
    "print(f\"Ratings Data Shape: {ratings.shape} \\n\")\n",
    "print(f\"{ratings.dtypes}\\n\")\n",
    "print(ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books Data Shape: (271360, 8) \n",
      "\n",
      "ISBN                   object\n",
      "Book-Title             object\n",
      "Book-Author            object\n",
      "Year-Of-Publication    object\n",
      "Publisher              object\n",
      "Image-URL-S            object\n",
      "Image-URL-M            object\n",
      "Image-URL-L            object\n",
      "dtype: object\n",
      "\n",
      "         ISBN            Book-Title           Book-Author Year-Of-Publication  \\\n",
      "0  0195153448   Classical Mythology    Mark P. O. Morford                2002   \n",
      "1  0002005018          Clara Callan  Richard Bruce Wright                2001   \n",
      "2  0060973129  Decision in Normandy          Carlo D'Este                1991   \n",
      "\n",
      "                 Publisher                                        Image-URL-S  \\\n",
      "0  Oxford University Press  http://images.amazon.com/images/P/0195153448.0...   \n",
      "1    HarperFlamingo Canada  http://images.amazon.com/images/P/0002005018.0...   \n",
      "2          HarperPerennial  http://images.amazon.com/images/P/0060973129.0...   \n",
      "\n",
      "                                         Image-URL-M  \\\n",
      "0  http://images.amazon.com/images/P/0195153448.0...   \n",
      "1  http://images.amazon.com/images/P/0002005018.0...   \n",
      "2  http://images.amazon.com/images/P/0060973129.0...   \n",
      "\n",
      "                                         Image-URL-L  \n",
      "0  http://images.amazon.com/images/P/0195153448.0...  \n",
      "1  http://images.amazon.com/images/P/0002005018.0...  \n",
      "2  http://images.amazon.com/images/P/0060973129.0...  \n",
      "Nan-values by column\n",
      "ISBN                   0\n",
      "Book-Title             0\n",
      "Book-Author            2\n",
      "Year-Of-Publication    0\n",
      "Publisher              2\n",
      "Image-URL-S            0\n",
      "Image-URL-M            0\n",
      "Image-URL-L            3\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qc/8fy08h5s33n4rrmz09_8bv680000gn/T/ipykernel_12836/3035873185.py:1: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  books = pd.read_csv(\"Data/Books.csv\")\n"
     ]
    }
   ],
   "source": [
    "books = pd.read_csv(\"Data/Books.csv\")\n",
    "print(f\"Books Data Shape: {books.shape} \\n\")\n",
    "print(f\"{books.dtypes}\\n\")\n",
    "print(books.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nan-values by column\n",
      "ISBN                   0\n",
      "Book-Title             0\n",
      "Book-Author            2\n",
      "Year-Of-Publication    0\n",
      "Publisher              2\n",
      "Image-URL-S            0\n",
      "Image-URL-M            0\n",
      "Image-URL-L            3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Nan-values by column')\n",
    "print(books.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users Data Shape: (278858, 3) \n",
      "\n",
      "User-ID       int64\n",
      "Location     object\n",
      "Age         float64\n",
      "dtype: object\n",
      "\n",
      "   User-ID                            Location   Age\n",
      "0        1                  nyc, new york, usa   NaN\n",
      "1        2           stockton, california, usa  18.0\n",
      "2        3     moscow, yukon territory, russia   NaN\n",
      "3        4           porto, v.n.gaia, portugal  17.0\n",
      "4        5  farnborough, hants, united kingdom   NaN\n",
      "Nan-values by column\n",
      "User-ID          0\n",
      "Location         0\n",
      "Age         110762\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "users = pd.read_csv(\"Data/Users.csv\")\n",
    "print(f\"Users Data Shape: {users.shape} \\n\")\n",
    "print(f\"{users.dtypes}\\n\")\n",
    "print(users.head())\n",
    "\n",
    "print('Nan-values by column')\n",
    "print(users.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 105283 unique users, and 340556 unique books in the ratings dataset.\n",
      "There are 20.673545613643572% of books in the graph missing in the books data\n"
     ]
    }
   ],
   "source": [
    "# We will only use users and books present in the ratings dataset \n",
    "lessen_user_ids = {userid: idx for idx, userid in enumerate(ratings['User-ID'].unique())} #renumber IDs to reduce inactive users\n",
    "ratings['New-User-ID'] = ratings['User-ID'].map(lessen_user_ids)\n",
    "user_ids = list(ratings['New-User-ID'].unique())\n",
    "num_users = len(set(user_ids))\n",
    "\n",
    "# Map book identifiers (ISBN) to a unique integer identifier for datatype compatibility of dgl\n",
    "isbn_to_id = {isbn: idx for idx, isbn in enumerate(ratings['ISBN'].unique())}\n",
    "ratings['Book-ID'] = ratings['ISBN'].map(isbn_to_id)\n",
    "book_ids = list(ratings['Book-ID'].unique())\n",
    "num_books = len(set(book_ids))\n",
    "\n",
    "print(f'There are {len(user_ids)} unique users, and {len(book_ids)} unique books in the ratings dataset.')\n",
    " \n",
    "# Remove users and books not included in the ratings dataset\n",
    "books['Book-ID'] = books['ISBN'].map(isbn_to_id)\n",
    "books_clean = books[books['Book-ID'].isin(book_ids)]\n",
    "books_clean_ids = books_clean['Book-ID'].unique()\n",
    "percent_books_missing = (num_books-len(books_clean_ids))/num_books*100\n",
    "\n",
    "print(f'There are {percent_books_missing}% of books in the graph missing in the books data')\n",
    "\n",
    "users['New-User-ID'] = users['User-ID'].map(lessen_user_ids)\n",
    "users_clean = users[users['New-User-ID'].isin(user_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1/5 of the books that have rating information do not have further information on the books dataset. However, as our objective is to investivate an user-based recommender system, this is irrelevant. We are able to embed the age and location data of users. As the age data is sparse, location data will be our main source of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes={'book': 340556, 'user': 105283},\n",
      "      num_edges={('user', 'rating', 'book'): 1149780},\n",
      "      metagraph=[('user', 'book', 'rating')])\n"
     ]
    }
   ],
   "source": [
    "# Make graph\n",
    "src = torch.tensor(ratings['New-User-ID'].values)\n",
    "dst = torch.tensor(ratings['Book-ID-offset'].values)\n",
    "\n",
    "edges = {\n",
    "    ('user', 'rating', 'book'): (src, dst)\n",
    "}\n",
    "\n",
    "g = dgl.heterograph(edges, num_nodes_dict={'user': num_users, 'book': num_books})\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weigh the edges by ratings\n",
    "rating_data = ratings['Book-Rating'].values\n",
    "ratings_tensor = torch.tensor(rating_data, dtype=torch.float32)\n",
    "g.edges['rating'].data['rating'] = ratings_tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add age to user feature\n",
    "ages = users_clean['Age'].values\n",
    "ages_tensor = torch.tensor(ages, dtype=torch.float32)\n",
    "g.nodes['user'].data['age'] = ages_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract the country from the location by obtaining the expression after the last comma in e.g. nyc, new york, usa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qc/8fy08h5s33n4rrmz09_8bv680000gn/T/ipykernel_12836/246620300.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  users_clean['Country'] = users_clean['Location'].str.rsplit(',', n=1).str[-1].str.strip()\n",
      "/var/folders/qc/8fy08h5s33n4rrmz09_8bv680000gn/T/ipykernel_12836/246620300.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  users_clean['CountryId'] = users_clean['Country'].map(country_ids)\n"
     ]
    }
   ],
   "source": [
    "users_clean['Country'] = users_clean['Location'].str.rsplit(',', n=1).str[-1].str.strip()\n",
    "country_counts = users_clean['Country'].value_counts(normalize=True) \n",
    "\n",
    "# We see that less frequent locations do not always contain country names, so we remove values of locations representing less than 1%\n",
    "rare_countries = country_counts[country_counts < 0.01].index\n",
    "users_clean.loc[users_clean['Country'].isin(rare_countries), 'Country'] = np.nan\n",
    "\n",
    "country_ids = {country: idx for idx, country in enumerate(users_clean['Country'].unique())}  # map country to a unique integer\n",
    "users_clean['CountryId'] = users_clean['Country'].map(country_ids)\n",
    "countries = users_clean['CountryId'].values\n",
    "countries_tensor = torch.tensor(countries, dtype=torch.float32)\n",
    "g.nodes['user'].data['country'] = countries_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NodeSpace(data={'age': tensor([18., nan, nan,  ..., 33., 32., nan]), 'country': tensor([0., 0., 1.,  ..., 0., 8., 0.])})\n"
     ]
    }
   ],
   "source": [
    "print(g.nodes['user'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
