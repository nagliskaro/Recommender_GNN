{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Book Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "from dgl.nn import GraphConv\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings Data Shape: (1149780, 3) \n",
      "\n",
      "User-ID         int64\n",
      "ISBN           object\n",
      "Book-Rating     int64\n",
      "dtype: object\n",
      "\n",
      "   User-ID        ISBN  Book-Rating\n",
      "0   276725  034545104X            0\n",
      "1   276726  0155061224            5\n",
      "2   276727  0446520802            0\n",
      "3   276729  052165615X            3\n",
      "4   276729  0521795028            6\n"
     ]
    }
   ],
   "source": [
    "ratings = pd.read_csv(\"Data/Ratings.csv\")\n",
    "print(f\"Ratings Data Shape: {ratings.shape} \\n\")\n",
    "print(f\"{ratings.dtypes}\\n\")\n",
    "print(ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cq/98zwd04x4s17ykcqft6vk5fw0000gn/T/ipykernel_28264/2859729214.py:1: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  books = pd.read_csv(\"Data/Books.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books Data Shape: (271360, 8) \n",
      "\n",
      "ISBN                   object\n",
      "Book-Title             object\n",
      "Book-Author            object\n",
      "Year-Of-Publication    object\n",
      "Publisher              object\n",
      "Image-URL-S            object\n",
      "Image-URL-M            object\n",
      "Image-URL-L            object\n",
      "dtype: object\n",
      "\n",
      "         ISBN            Book-Title           Book-Author Year-Of-Publication  \\\n",
      "0  0195153448   Classical Mythology    Mark P. O. Morford                2002   \n",
      "1  0002005018          Clara Callan  Richard Bruce Wright                2001   \n",
      "2  0060973129  Decision in Normandy          Carlo D'Este                1991   \n",
      "\n",
      "                 Publisher                                        Image-URL-S  \\\n",
      "0  Oxford University Press  http://images.amazon.com/images/P/0195153448.0...   \n",
      "1    HarperFlamingo Canada  http://images.amazon.com/images/P/0002005018.0...   \n",
      "2          HarperPerennial  http://images.amazon.com/images/P/0060973129.0...   \n",
      "\n",
      "                                         Image-URL-M  \\\n",
      "0  http://images.amazon.com/images/P/0195153448.0...   \n",
      "1  http://images.amazon.com/images/P/0002005018.0...   \n",
      "2  http://images.amazon.com/images/P/0060973129.0...   \n",
      "\n",
      "                                         Image-URL-L  \n",
      "0  http://images.amazon.com/images/P/0195153448.0...  \n",
      "1  http://images.amazon.com/images/P/0002005018.0...  \n",
      "2  http://images.amazon.com/images/P/0060973129.0...  \n"
     ]
    }
   ],
   "source": [
    "books = pd.read_csv(\"Data/Books.csv\")\n",
    "print(f\"Books Data Shape: {books.shape} \\n\")\n",
    "print(f\"{books.dtypes}\\n\")\n",
    "print(books.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nan-values by column\n",
      "ISBN                   0\n",
      "Book-Title             0\n",
      "Book-Author            2\n",
      "Year-Of-Publication    0\n",
      "Publisher              2\n",
      "Image-URL-S            0\n",
      "Image-URL-M            0\n",
      "Image-URL-L            3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Nan-values by column')\n",
    "print(books.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users Data Shape: (278858, 3) \n",
      "\n",
      "User-ID       int64\n",
      "Location     object\n",
      "Age         float64\n",
      "dtype: object\n",
      "\n",
      "   User-ID                            Location   Age\n",
      "0        1                  nyc, new york, usa   NaN\n",
      "1        2           stockton, california, usa  18.0\n",
      "2        3     moscow, yukon territory, russia   NaN\n",
      "3        4           porto, v.n.gaia, portugal  17.0\n",
      "4        5  farnborough, hants, united kingdom   NaN\n",
      "Nan-values by column\n",
      "User-ID          0\n",
      "Location         0\n",
      "Age         110762\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "users = pd.read_csv(\"Data/Users.csv\")\n",
    "print(f\"Users Data Shape: {users.shape} \\n\")\n",
    "print(f\"{users.dtypes}\\n\")\n",
    "print(users.head())\n",
    "\n",
    "print('Nan-values by column')\n",
    "print(users.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 105283 unique users, and 340556 unique books in the ratings dataset.\n",
      "There are 20.673545613643572% of books in the graph missing in the books data\n"
     ]
    }
   ],
   "source": [
    "# We will only use users and books present in the ratings dataset \n",
    "lessen_user_ids = {userid: idx for idx, userid in enumerate(ratings['User-ID'].unique())} #renumber IDs to reduce inactive users\n",
    "ratings['New-User-ID'] = ratings['User-ID'].map(lessen_user_ids)\n",
    "user_ids = list(ratings['New-User-ID'].unique())\n",
    "num_users = len(set(user_ids))\n",
    "\n",
    "# Map book identifiers (ISBN) to a unique integer identifier for datatype compatibility of dgl\n",
    "isbn_to_id = {isbn: idx for idx, isbn in enumerate(ratings['ISBN'].unique())}\n",
    "ratings['Book-ID'] = ratings['ISBN'].map(isbn_to_id)\n",
    "book_ids = list(ratings['Book-ID'].unique())\n",
    "num_books = len(set(book_ids))\n",
    "\n",
    "print(f'There are {len(user_ids)} unique users, and {len(book_ids)} unique books in the ratings dataset.')\n",
    " \n",
    "# Remove users and books not included in the ratings dataset\n",
    "books['Book-ID'] = books['ISBN'].map(isbn_to_id)\n",
    "books_clean = books[books['Book-ID'].isin(book_ids)]\n",
    "books_clean_ids = books_clean['Book-ID'].unique()\n",
    "percent_books_missing = (num_books-len(books_clean_ids))/num_books*100\n",
    "\n",
    "print(f'There are {percent_books_missing}% of books in the graph missing in the books data')\n",
    "\n",
    "users['New-User-ID'] = users['User-ID'].map(lessen_user_ids)\n",
    "users_clean = users[users['New-User-ID'].isin(user_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1/5 of the books that have rating information do not have further information on the books dataset. However, as our objective is to investivate an user-based recommender system, this is irrelevant. We are able to embed the age and location data of users. As the age data is sparse, location data will be our main source of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes={'book': 340556, 'user': 105283},\n",
      "      num_edges={('user', 'rating', 'book'): 1149780},\n",
      "      metagraph=[('user', 'book', 'rating')])\n"
     ]
    }
   ],
   "source": [
    "# Make graph\n",
    "src = torch.tensor(ratings['New-User-ID'].values)\n",
    "dst = torch.tensor(ratings['Book-ID'].values)\n",
    "\n",
    "edges = {\n",
    "    ('user', 'rating', 'book'): (src, dst)\n",
    "}\n",
    "\n",
    "g = dgl.heterograph(edges, num_nodes_dict={'user': num_users, 'book': num_books})\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weigh the edges by ratings\n",
    "rating_data = ratings['Book-Rating'].values\n",
    "ratings_tensor = torch.tensor(rating_data, dtype=torch.float32)\n",
    "g.edges['rating'].data['rating'] = ratings_tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add age to user feature\n",
    "ages = users_clean['Age'].values\n",
    "ages_tensor = torch.tensor(ages, dtype=torch.float32)\n",
    "g.nodes['user'].data['age'] = ages_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract the country from the location by obtaining the expression after the last comma in e.g. nyc, new york, usa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cq/98zwd04x4s17ykcqft6vk5fw0000gn/T/ipykernel_28264/246620300.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  users_clean['Country'] = users_clean['Location'].str.rsplit(',', n=1).str[-1].str.strip()\n",
      "/var/folders/cq/98zwd04x4s17ykcqft6vk5fw0000gn/T/ipykernel_28264/246620300.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  users_clean['CountryId'] = users_clean['Country'].map(country_ids)\n"
     ]
    }
   ],
   "source": [
    "users_clean['Country'] = users_clean['Location'].str.rsplit(',', n=1).str[-1].str.strip()\n",
    "country_counts = users_clean['Country'].value_counts(normalize=True) \n",
    "\n",
    "# We see that less frequent locations do not always contain country names, so we remove values of locations representing less than 1%\n",
    "rare_countries = country_counts[country_counts < 0.01].index\n",
    "users_clean.loc[users_clean['Country'].isin(rare_countries), 'Country'] = np.nan\n",
    "\n",
    "country_ids = {country: idx for idx, country in enumerate(users_clean['Country'].unique())}  # map country to a unique integer\n",
    "users_clean['CountryId'] = users_clean['Country'].map(country_ids)\n",
    "countries = users_clean['CountryId'].values\n",
    "countries_tensor = torch.tensor(countries, dtype=torch.float32)\n",
    "g.nodes['user'].data['country'] = countries_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NodeSpace(data={'age': tensor([18., nan, nan,  ..., 33., 32., nan]), 'country': tensor([0., 0., 1.,  ..., 0., 8., 0.])})\n",
      "NodeSpace(data={})\n"
     ]
    }
   ],
   "source": [
    "print(g.nodes['user'])\n",
    "print(g.nodes['book'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic graph info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes={'book': 340556, 'user': 105283},\n",
      "      num_edges={('user', 'rating', 'book'): 1149780},\n",
      "      metagraph=[('user', 'book', 'rating')])\n",
      "Number of users: 105283\n",
      "Number of books: 340556\n",
      "Number of ratings: 1149780\n"
     ]
    }
   ],
   "source": [
    "print(g)  # Prints the basic info of the graph, such as number of nodes and edges per type\n",
    "\n",
    "# Print number of nodes for each type\n",
    "print(\"Number of users:\", g.number_of_nodes('user'))\n",
    "print(\"Number of books:\", g.number_of_nodes('book'))\n",
    "\n",
    "# Print number of edges\n",
    "print(\"Number of ratings:\", g.number_of_edges('rating'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node and Edge feature inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User features: dict_keys(['age', 'country'])\n",
      "Book features: dict_keys([])\n",
      "Edge features: dict_keys(['rating'])\n",
      "Sample user ages: tensor([18., nan, nan, nan, 26.])\n",
      "Sample ratings: tensor([0., 5., 0., 3., 6.])\n"
     ]
    }
   ],
   "source": [
    "# Print user node features\n",
    "print(\"User features:\", g.nodes['user'].data.keys())\n",
    "\n",
    "# Print book node features, if any\n",
    "print(\"Book features:\", g.nodes['book'].data.keys())\n",
    "\n",
    "# Print edge features\n",
    "print(\"Edge features:\", g.edges['rating'].data.keys())\n",
    "\n",
    "# Example to print specific feature details:\n",
    "print(\"Sample user ages:\", g.nodes['user'].data['age'][:5])  # prints first 5 user ages\n",
    "print(\"Sample ratings:\", g.edges['rating'].data['rating'][:5])  # prints first 5 ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminate isolated nodes if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "compact_g = dgl.compact_graphs(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create synthetic features for book based on degree of the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_in_degrees = g.in_degrees(etype=('user', 'rating', 'book')).float().unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.nodes['book'].data['in_degree'] = book_in_degrees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the GNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNRecommender(nn.Module):\n",
    "    def __init__(self, user_feats, book_feats, hidden_size, num_classes):\n",
    "        super(GNNRecommender, self).__init__()\n",
    "        self.user_conv = GraphConv(user_feats, hidden_size)\n",
    "        self.book_conv = GraphConv(book_feats, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, g, user_features, book_features):\n",
    "        user_h = F.relu(self.user_conv(g, user_features))\n",
    "        book_h = F.relu(self.book_conv(g, book_features))\n",
    "        user_book_h = user_h + book_h\n",
    "        return self.fc(user_book_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_tensor = g.nodes['user'].data['age'].unsqueeze(1)\n",
    "country_tensor = g.nodes['user'].data['country'].unsqueeze(1)\n",
    "user_feats = torch.cat([age_tensor, country_tensor], dim=1)\n",
    "user_feat_dim = user_feats.shape[1]  # the size of user feature\n",
    "book_feats = g.nodes['book'].data['in_degree'].shape[1]  # the size of book features\n",
    "\n",
    "hidden_size = 32\n",
    "num_classes = 1  # predicting a single rating value\n",
    "\n",
    "model = GNNRecommender(user_feat_dim, book_feats, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split graph for training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_graph(g, proportion=0.8):\n",
    "    # Split edges randomly for training and validation\n",
    "    num_edges = g.number_of_edges('rating')\n",
    "    all_edges = np.arange(num_edges)\n",
    "    np.random.shuffle(all_edges)\n",
    "    \n",
    "    train_size = int(num_edges * proportion)\n",
    "    train_edges = all_edges[:train_size]\n",
    "    val_edges = all_edges[train_size:]\n",
    "    \n",
    "    # Create subgraphs based on the edges\n",
    "    g_train = dgl.edge_subgraph(g, train_edges, relabel_nodes=False)\n",
    "    g_val = dgl.edge_subgraph(g, val_edges, relabel_nodes=False)\n",
    "    \n",
    "    return g_train, g_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_train, g_val = split_graph(g, proportion=0.8)\n",
    "\n",
    "# Get the features and ratings for each set\n",
    "age_tensor_train = g_train.nodes['user'].data['age'].unsqueeze(1)\n",
    "country_tensor_train = g_train.nodes['user'].data['country'].unsqueeze(1)\n",
    "user_features_train = torch.cat([age_tensor_train, country_tensor_train], dim=1)\n",
    "book_features_train = g_train.nodes['book'].data['in_degree']\n",
    "ratings_train = g_train.edges['rating'].data['rating']\n",
    "\n",
    "age_tensor_val = g_val.nodes['user'].data['age'].unsqueeze(1)\n",
    "country_tensor_val = g_val.nodes['user'].data['country'].unsqueeze(1)\n",
    "user_features_val = torch.cat([age_tensor_train, country_tensor_train], dim=1)\n",
    "book_features_val = g_val.nodes['book'].data['in_degree']\n",
    "ratings_val = g_val.edges['rating'].data['rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, g, user_features, book_features, labels, optimizer, criterion):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(g, user_features, book_features)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "DGLError",
     "evalue": "There are 0-in-degree nodes in the graph, output for those nodes will be invalid. This is harmful for some applications, causing silent performance regression. Adding self-loop on the input graph by calling `g = dgl.add_self_loop(g)` will resolve the issue. Setting ``allow_zero_in_degree`` to be `True` when constructing this module will suppress the check and let the code run.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDGLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m  \u001b[38;5;66;03m# or however many epochs you deem necessary\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 4\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_features_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbook_features_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mratings_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[69], line 4\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, g, user_features, book_features, labels, optimizer, criterion)\u001b[0m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      3\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 4\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbook_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m      6\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Documents/3rd year AUC/TM/GNN/env_GNN/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/3rd year AUC/TM/GNN/env_GNN/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[46], line 9\u001b[0m, in \u001b[0;36mGNNRecommender.forward\u001b[0;34m(self, g, user_features, book_features)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, g, user_features, book_features):\n\u001b[0;32m----> 9\u001b[0m     user_h \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_features\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     10\u001b[0m     book_h \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbook_conv(g, book_features))\n\u001b[1;32m     11\u001b[0m     user_book_h \u001b[38;5;241m=\u001b[39m user_h \u001b[38;5;241m+\u001b[39m book_h\n",
      "File \u001b[0;32m~/Documents/3rd year AUC/TM/GNN/env_GNN/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/3rd year AUC/TM/GNN/env_GNN/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/3rd year AUC/TM/GNN/env_GNN/lib/python3.11/site-packages/dgl/nn/pytorch/conv/graphconv.py:408\u001b[0m, in \u001b[0;36mGraphConv.forward\u001b[0;34m(self, graph, feat, weight, edge_weight)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_allow_zero_in_degree:\n\u001b[1;32m    407\u001b[0m     \u001b[39mif\u001b[39;00m (graph\u001b[39m.\u001b[39min_degrees() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39many():\n\u001b[0;32m--> 408\u001b[0m         \u001b[39mraise\u001b[39;00m DGLError(\n\u001b[1;32m    409\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThere are 0-in-degree nodes in the graph, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39moutput for those nodes will be invalid. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThis is harmful for some applications, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    412\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mcausing silent performance regression. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    413\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mAdding self-loop on the input graph by \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    414\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mcalling `g = dgl.add_self_loop(g)` will resolve \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    415\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mthe issue. Setting ``allow_zero_in_degree`` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    416\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mto be `True` when constructing this module will \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    417\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39msuppress the check and let the code run.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    418\u001b[0m         )\n\u001b[1;32m    419\u001b[0m aggregate_fn \u001b[39m=\u001b[39m fn\u001b[39m.\u001b[39mcopy_u(\u001b[39m\"\u001b[39m\u001b[39mh\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mm\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    420\u001b[0m \u001b[39mif\u001b[39;00m edge_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mDGLError\u001b[0m: There are 0-in-degree nodes in the graph, output for those nodes will be invalid. This is harmful for some applications, causing silent performance regression. Adding self-loop on the input graph by calling `g = dgl.add_self_loop(g)` will resolve the issue. Setting ``allow_zero_in_degree`` to be `True` when constructing this module will suppress the check and let the code run."
     ]
    }
   ],
   "source": [
    "num_epochs = 50  # or however many epochs you deem necessary\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loss = train(model, g_train, user_features_train, book_features_train, ratings_train, optimizer, criterion)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, g, user_features, book_features, labels, criterion):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(g, user_features, book_features)\n",
    "        loss = criterion(outputs, labels)\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation loss\n",
    "validation_loss = evaluate(model, g_val, user_features_val, book_features_val, ratings_val, criterion)\n",
    "print(f'Validation Loss: {validation_loss}')a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('env_GNN': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "8f6377febe87314814c7b7161cea679ad38a9298f17e15a391a898e937fe96e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
