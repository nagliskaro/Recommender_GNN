{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Book Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "from dgl.nn import GraphConv\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276725</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276726</td>\n",
       "      <td>0155061224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276727</td>\n",
       "      <td>0446520802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276729</td>\n",
       "      <td>052165615X</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276729</td>\n",
       "      <td>0521795028</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149775</th>\n",
       "      <td>276704</td>\n",
       "      <td>1563526298</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149776</th>\n",
       "      <td>276706</td>\n",
       "      <td>0679447156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149777</th>\n",
       "      <td>276709</td>\n",
       "      <td>0515107662</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149778</th>\n",
       "      <td>276721</td>\n",
       "      <td>0590442449</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149779</th>\n",
       "      <td>276723</td>\n",
       "      <td>05162443314</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1149780 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         User-ID         ISBN  Book-Rating\n",
       "0         276725   034545104X            0\n",
       "1         276726   0155061224            5\n",
       "2         276727   0446520802            0\n",
       "3         276729   052165615X            3\n",
       "4         276729   0521795028            6\n",
       "...          ...          ...          ...\n",
       "1149775   276704   1563526298            9\n",
       "1149776   276706   0679447156            0\n",
       "1149777   276709   0515107662           10\n",
       "1149778   276721   0590442449           10\n",
       "1149779   276723  05162443314            8\n",
       "\n",
       "[1149780 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv(\"Data/Ratings.csv\")\n",
    "#print(f\"{ratings.dtypes}\\n\")\n",
    "#print(ratings.head())\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     716109\n",
       "8     103736\n",
       "10     78610\n",
       "7      76457\n",
       "9      67541\n",
       "5      50974\n",
       "6      36924\n",
       "4       8904\n",
       "3       5996\n",
       "2       2759\n",
       "1       1770\n",
       "Name: Book-Rating, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings[\"Book-Rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>W. W. Norton &amp;amp; Company</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271355</th>\n",
       "      <td>0440400988</td>\n",
       "      <td>There's a Bat in Bunk Five</td>\n",
       "      <td>Paula Danziger</td>\n",
       "      <td>1988</td>\n",
       "      <td>Random House Childrens Pub (Mm)</td>\n",
       "      <td>http://images.amazon.com/images/P/0440400988.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0440400988.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0440400988.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271356</th>\n",
       "      <td>0525447644</td>\n",
       "      <td>From One to One Hundred</td>\n",
       "      <td>Teri Sloat</td>\n",
       "      <td>1991</td>\n",
       "      <td>Dutton Books</td>\n",
       "      <td>http://images.amazon.com/images/P/0525447644.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0525447644.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0525447644.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271357</th>\n",
       "      <td>006008667X</td>\n",
       "      <td>Lily Dale : The True Story of the Town that Ta...</td>\n",
       "      <td>Christine Wicker</td>\n",
       "      <td>2004</td>\n",
       "      <td>HarperSanFrancisco</td>\n",
       "      <td>http://images.amazon.com/images/P/006008667X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/006008667X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/006008667X.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271358</th>\n",
       "      <td>0192126040</td>\n",
       "      <td>Republic (World's Classics)</td>\n",
       "      <td>Plato</td>\n",
       "      <td>1996</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0192126040.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0192126040.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0192126040.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271359</th>\n",
       "      <td>0767409752</td>\n",
       "      <td>A Guided Tour of Rene Descartes' Meditations o...</td>\n",
       "      <td>Christopher  Biffle</td>\n",
       "      <td>2000</td>\n",
       "      <td>McGraw-Hill Humanities/Social Sciences/Languages</td>\n",
       "      <td>http://images.amazon.com/images/P/0767409752.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0767409752.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0767409752.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>271360 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ISBN                                         Book-Title  \\\n",
       "0       0195153448                                Classical Mythology   \n",
       "1       0002005018                                       Clara Callan   \n",
       "2       0060973129                               Decision in Normandy   \n",
       "3       0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "4       0393045218                             The Mummies of Urumchi   \n",
       "...            ...                                                ...   \n",
       "271355  0440400988                         There's a Bat in Bunk Five   \n",
       "271356  0525447644                            From One to One Hundred   \n",
       "271357  006008667X  Lily Dale : The True Story of the Town that Ta...   \n",
       "271358  0192126040                        Republic (World's Classics)   \n",
       "271359  0767409752  A Guided Tour of Rene Descartes' Meditations o...   \n",
       "\n",
       "                 Book-Author Year-Of-Publication  \\\n",
       "0         Mark P. O. Morford                2002   \n",
       "1       Richard Bruce Wright                2001   \n",
       "2               Carlo D'Este                1991   \n",
       "3           Gina Bari Kolata                1999   \n",
       "4            E. J. W. Barber                1999   \n",
       "...                      ...                 ...   \n",
       "271355        Paula Danziger                1988   \n",
       "271356            Teri Sloat                1991   \n",
       "271357      Christine Wicker                2004   \n",
       "271358                 Plato                1996   \n",
       "271359   Christopher  Biffle                2000   \n",
       "\n",
       "                                               Publisher  \\\n",
       "0                                Oxford University Press   \n",
       "1                                  HarperFlamingo Canada   \n",
       "2                                        HarperPerennial   \n",
       "3                                   Farrar Straus Giroux   \n",
       "4                             W. W. Norton &amp; Company   \n",
       "...                                                  ...   \n",
       "271355                   Random House Childrens Pub (Mm)   \n",
       "271356                                      Dutton Books   \n",
       "271357                                HarperSanFrancisco   \n",
       "271358                           Oxford University Press   \n",
       "271359  McGraw-Hill Humanities/Social Sciences/Languages   \n",
       "\n",
       "                                              Image-URL-S  \\\n",
       "0       http://images.amazon.com/images/P/0195153448.0...   \n",
       "1       http://images.amazon.com/images/P/0002005018.0...   \n",
       "2       http://images.amazon.com/images/P/0060973129.0...   \n",
       "3       http://images.amazon.com/images/P/0374157065.0...   \n",
       "4       http://images.amazon.com/images/P/0393045218.0...   \n",
       "...                                                   ...   \n",
       "271355  http://images.amazon.com/images/P/0440400988.0...   \n",
       "271356  http://images.amazon.com/images/P/0525447644.0...   \n",
       "271357  http://images.amazon.com/images/P/006008667X.0...   \n",
       "271358  http://images.amazon.com/images/P/0192126040.0...   \n",
       "271359  http://images.amazon.com/images/P/0767409752.0...   \n",
       "\n",
       "                                              Image-URL-M  \\\n",
       "0       http://images.amazon.com/images/P/0195153448.0...   \n",
       "1       http://images.amazon.com/images/P/0002005018.0...   \n",
       "2       http://images.amazon.com/images/P/0060973129.0...   \n",
       "3       http://images.amazon.com/images/P/0374157065.0...   \n",
       "4       http://images.amazon.com/images/P/0393045218.0...   \n",
       "...                                                   ...   \n",
       "271355  http://images.amazon.com/images/P/0440400988.0...   \n",
       "271356  http://images.amazon.com/images/P/0525447644.0...   \n",
       "271357  http://images.amazon.com/images/P/006008667X.0...   \n",
       "271358  http://images.amazon.com/images/P/0192126040.0...   \n",
       "271359  http://images.amazon.com/images/P/0767409752.0...   \n",
       "\n",
       "                                              Image-URL-L  \n",
       "0       http://images.amazon.com/images/P/0195153448.0...  \n",
       "1       http://images.amazon.com/images/P/0002005018.0...  \n",
       "2       http://images.amazon.com/images/P/0060973129.0...  \n",
       "3       http://images.amazon.com/images/P/0374157065.0...  \n",
       "4       http://images.amazon.com/images/P/0393045218.0...  \n",
       "...                                                   ...  \n",
       "271355  http://images.amazon.com/images/P/0440400988.0...  \n",
       "271356  http://images.amazon.com/images/P/0525447644.0...  \n",
       "271357  http://images.amazon.com/images/P/006008667X.0...  \n",
       "271358  http://images.amazon.com/images/P/0192126040.0...  \n",
       "271359  http://images.amazon.com/images/P/0767409752.0...  \n",
       "\n",
       "[271360 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books = pd.read_csv(\"Data/Books.csv\", dtype={3: str})\n",
    "#print(f\"Books Data Shape: {books.shape} \\n\")\n",
    "#print(f\"{books.dtypes}\\n\")\n",
    "#print(books.head(3))\n",
    "\n",
    "books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nan-values by column\n",
      "ISBN                   0\n",
      "Book-Title             0\n",
      "Book-Author            1\n",
      "Year-Of-Publication    0\n",
      "Publisher              2\n",
      "Image-URL-S            0\n",
      "Image-URL-M            0\n",
      "Image-URL-L            3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Nan-values by column')\n",
    "print(books.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>nyc, new york, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>stockton, california, usa</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>moscow, yukon territory, russia</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>porto, v.n.gaia, portugal</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>farnborough, hants, united kingdom</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278853</th>\n",
       "      <td>278854</td>\n",
       "      <td>portland, oregon, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278854</th>\n",
       "      <td>278855</td>\n",
       "      <td>tacoma, washington, united kingdom</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278855</th>\n",
       "      <td>278856</td>\n",
       "      <td>brampton, ontario, canada</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278856</th>\n",
       "      <td>278857</td>\n",
       "      <td>knoxville, tennessee, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278857</th>\n",
       "      <td>278858</td>\n",
       "      <td>dublin, n/a, ireland</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>278858 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        User-ID                            Location   Age\n",
       "0             1                  nyc, new york, usa   NaN\n",
       "1             2           stockton, california, usa  18.0\n",
       "2             3     moscow, yukon territory, russia   NaN\n",
       "3             4           porto, v.n.gaia, portugal  17.0\n",
       "4             5  farnborough, hants, united kingdom   NaN\n",
       "...         ...                                 ...   ...\n",
       "278853   278854               portland, oregon, usa   NaN\n",
       "278854   278855  tacoma, washington, united kingdom  50.0\n",
       "278855   278856           brampton, ontario, canada   NaN\n",
       "278856   278857           knoxville, tennessee, usa   NaN\n",
       "278857   278858                dublin, n/a, ireland   NaN\n",
       "\n",
       "[278858 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = pd.read_csv(\"Data/Users.csv\")\n",
    "#print(f\"Users Data Shape: {users.shape} \\n\")\n",
    "#print(f\"{users.dtypes}\\n\")\n",
    "#print(users.head())\n",
    "#print('Nan-values by column')\n",
    "#print(users.isna().sum())\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 105283 unique users, and 340556 unique books in the ratings dataset.\n",
      "There are around 21.0% of books in the graph missing in the books data\n"
     ]
    }
   ],
   "source": [
    "# We will only use users and books present in the ratings dataset \n",
    "lessen_user_ids = {userid: idx for idx, userid in enumerate(ratings['User-ID'].unique())} #renumber IDs to reduce inactive users\n",
    "ratings['New-User-ID'] = ratings['User-ID'].map(lessen_user_ids)\n",
    "user_ids = list(ratings['New-User-ID'].unique())\n",
    "num_users = len(set(user_ids))\n",
    "\n",
    "# Map book identifiers (ISBN) to a unique integer identifier for datatype compatibility of dgl\n",
    "isbn_to_id = {isbn: idx for idx, isbn in enumerate(ratings['ISBN'].unique())}\n",
    "ratings['Book-ID'] = ratings['ISBN'].map(isbn_to_id)\n",
    "book_ids = list(ratings['Book-ID'].unique())\n",
    "num_books = len(set(book_ids))\n",
    "\n",
    "print(f'There are {len(user_ids)} unique users, and {len(book_ids)} unique books in the ratings dataset.')\n",
    " \n",
    "# Remove users and books not included in the ratings dataset\n",
    "books['Book-ID'] = books['ISBN'].map(isbn_to_id)\n",
    "books_clean = books[books['Book-ID'].isin(book_ids)]\n",
    "books_clean_ids = books_clean['Book-ID'].unique()\n",
    "percent_books_missing = round((num_books-len(books_clean_ids))/num_books*100, 0)\n",
    "\n",
    "print(f'There are around {percent_books_missing}% of books in the graph missing in the books data')\n",
    "\n",
    "users['New-User-ID'] = users['User-ID'].map(lessen_user_ids)\n",
    "users_clean = users[users['New-User-ID'].isin(user_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1/5 of the books that have rating information do not have further information on the books dataset. However, as our objective is to investigate a user-based recommender system, this is irrelevant. We are able to embed the age and location data of users. As the age data is sparse, location data will be our main source of information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is based on [this Kaggle documentation](https://www.kaggle.com/code/gspmoreira/recommender-systems-in-python-101)\n",
    "\n",
    "\"This method makes automatic predictions (filtering) about the interests of a user by collecting preferences or taste information from many users (collaborating). The underlying assumption of the collaborative filtering approach is that if a person A has the same opinion as a person B on a set of items, A is more likely to have B's opinion for a given item than that of a randomly chosen person.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratings_with_book_titles = ratings.merge(books,on='ISBN')\n",
    "ratings_with_book_titles.drop(columns=[\"ISBN\",\"Image-URL-S\",\"Image-URL-M\"],axis=1,inplace=True)\n",
    "complete_df = ratings_with_book_titles.merge(users.drop(\"Age\", axis=1), on=\"User-ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>New-User-ID_x</th>\n",
       "      <th>Book-ID_x</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-L</th>\n",
       "      <th>Book-ID_y</th>\n",
       "      <th>Location</th>\n",
       "      <th>New-User-ID_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276725</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "      <td>M. J. Rose</td>\n",
       "      <td>2002</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>usa</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2313</td>\n",
       "      <td>5</td>\n",
       "      <td>1655</td>\n",
       "      <td>0</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "      <td>M. J. Rose</td>\n",
       "      <td>2002</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>usa</td>\n",
       "      <td>1655.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2313</td>\n",
       "      <td>9</td>\n",
       "      <td>1655</td>\n",
       "      <td>383</td>\n",
       "      <td>Ender's Game (Ender Wiggins Saga (Paperback))</td>\n",
       "      <td>Orson Scott Card</td>\n",
       "      <td>1986</td>\n",
       "      <td>Tor Books</td>\n",
       "      <td>http://images.amazon.com/images/P/0812533550.0...</td>\n",
       "      <td>383.0</td>\n",
       "      <td>usa</td>\n",
       "      <td>1655.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2313</td>\n",
       "      <td>8</td>\n",
       "      <td>1655</td>\n",
       "      <td>443</td>\n",
       "      <td>In Cold Blood (Vintage International)</td>\n",
       "      <td>TRUMAN CAPOTE</td>\n",
       "      <td>1994</td>\n",
       "      <td>Vintage</td>\n",
       "      <td>http://images.amazon.com/images/P/0679745580.0...</td>\n",
       "      <td>443.0</td>\n",
       "      <td>usa</td>\n",
       "      <td>1655.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2313</td>\n",
       "      <td>9</td>\n",
       "      <td>1655</td>\n",
       "      <td>1313</td>\n",
       "      <td>Divine Secrets of the Ya-Ya Sisterhood : A Novel</td>\n",
       "      <td>Rebecca Wells</td>\n",
       "      <td>1996</td>\n",
       "      <td>HarperCollins</td>\n",
       "      <td>http://images.amazon.com/images/P/0060173289.0...</td>\n",
       "      <td>1313.0</td>\n",
       "      <td>usa</td>\n",
       "      <td>1655.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID  Book-Rating  New-User-ID_x  Book-ID_x  \\\n",
       "0   276725            0              0          0   \n",
       "1     2313            5           1655          0   \n",
       "2     2313            9           1655        383   \n",
       "3     2313            8           1655        443   \n",
       "4     2313            9           1655       1313   \n",
       "\n",
       "                                         Book-Title       Book-Author  \\\n",
       "0                              Flesh Tones: A Novel        M. J. Rose   \n",
       "1                              Flesh Tones: A Novel        M. J. Rose   \n",
       "2     Ender's Game (Ender Wiggins Saga (Paperback))  Orson Scott Card   \n",
       "3             In Cold Blood (Vintage International)     TRUMAN CAPOTE   \n",
       "4  Divine Secrets of the Ya-Ya Sisterhood : A Novel     Rebecca Wells   \n",
       "\n",
       "  Year-Of-Publication         Publisher  \\\n",
       "0                2002  Ballantine Books   \n",
       "1                2002  Ballantine Books   \n",
       "2                1986         Tor Books   \n",
       "3                1994           Vintage   \n",
       "4                1996     HarperCollins   \n",
       "\n",
       "                                         Image-URL-L  Book-ID_y Location  \\\n",
       "0  http://images.amazon.com/images/P/034545104X.0...        0.0      usa   \n",
       "1  http://images.amazon.com/images/P/034545104X.0...        0.0      usa   \n",
       "2  http://images.amazon.com/images/P/0812533550.0...      383.0      usa   \n",
       "3  http://images.amazon.com/images/P/0679745580.0...      443.0      usa   \n",
       "4  http://images.amazon.com/images/P/0060173289.0...     1313.0      usa   \n",
       "\n",
       "   New-User-ID_y  \n",
       "0            0.0  \n",
       "1         1655.0  \n",
       "2         1655.0  \n",
       "3         1655.0  \n",
       "4         1655.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_df['Location'] = complete_df['Location'].str.split(',').str[-1].str.strip()\n",
    "complete_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select user IDs with more than 200 book ratings\n",
    "min_ratings_threshold = 200\n",
    "\n",
    "# Count book ratings per user\n",
    "num_ratings_per_user = complete_df.groupby('User-ID')['Book-Rating'].count()\n",
    "\n",
    "# Filter users with more than the minimum threshold\n",
    "knowledgeable_user_ids = num_ratings_per_user[num_ratings_per_user > min_ratings_threshold].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter ratings from knowledgeable users\n",
    "knowledgeable_user_ratings = complete_df[complete_df['User-ID'].isin(knowledgeable_user_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_ratings_count_threshold=50\n",
    "rating_counts= knowledgeable_user_ratings.groupby('Book-Title').count()['Book-Rating']\n",
    "popular_books = rating_counts[rating_counts >= min_ratings_count_threshold].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ratings =  knowledgeable_user_ratings[knowledgeable_user_ratings['Book-Title'].isin(popular_books)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>User-ID</th>\n",
       "      <th>254</th>\n",
       "      <th>2276</th>\n",
       "      <th>2766</th>\n",
       "      <th>2977</th>\n",
       "      <th>3363</th>\n",
       "      <th>4017</th>\n",
       "      <th>4385</th>\n",
       "      <th>6251</th>\n",
       "      <th>6323</th>\n",
       "      <th>6543</th>\n",
       "      <th>...</th>\n",
       "      <th>271705</th>\n",
       "      <th>273979</th>\n",
       "      <th>274004</th>\n",
       "      <th>274061</th>\n",
       "      <th>274301</th>\n",
       "      <th>274308</th>\n",
       "      <th>275970</th>\n",
       "      <th>277427</th>\n",
       "      <th>277639</th>\n",
       "      <th>278418</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Book-Title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st to Die: A Novel</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2nd Chance</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 Blondes</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A Bend in the Road</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year of Wonders</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You Belong To Me</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zen and the Art of Motorcycle Maintenance: An Inquiry into Values</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zoya</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\O\\\" Is for Outlaw\"</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>706 rows × 810 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "User-ID                                             254     2276    2766    \\\n",
       "Book-Title                                                                   \n",
       "1984                                                   9.0     0.0     0.0   \n",
       "1st to Die: A Novel                                    0.0     0.0     0.0   \n",
       "2nd Chance                                             0.0    10.0     0.0   \n",
       "4 Blondes                                              0.0     0.0     0.0   \n",
       "A Bend in the Road                                     0.0     0.0     7.0   \n",
       "...                                                    ...     ...     ...   \n",
       "Year of Wonders                                        0.0     0.0     0.0   \n",
       "You Belong To Me                                       0.0     0.0     0.0   \n",
       "Zen and the Art of Motorcycle Maintenance: An I...     0.0     0.0     0.0   \n",
       "Zoya                                                   0.0     0.0     0.0   \n",
       "\\O\\\" Is for Outlaw\"                                    0.0     0.0     0.0   \n",
       "\n",
       "User-ID                                             2977    3363    4017    \\\n",
       "Book-Title                                                                   \n",
       "1984                                                   0.0     0.0     0.0   \n",
       "1st to Die: A Novel                                    0.0     0.0     0.0   \n",
       "2nd Chance                                             0.0     0.0     0.0   \n",
       "4 Blondes                                              0.0     0.0     0.0   \n",
       "A Bend in the Road                                     0.0     0.0     0.0   \n",
       "...                                                    ...     ...     ...   \n",
       "Year of Wonders                                        7.0     0.0     0.0   \n",
       "You Belong To Me                                       0.0     0.0     0.0   \n",
       "Zen and the Art of Motorcycle Maintenance: An I...     0.0     0.0     0.0   \n",
       "Zoya                                                   0.0     0.0     0.0   \n",
       "\\O\\\" Is for Outlaw\"                                    0.0     0.0     0.0   \n",
       "\n",
       "User-ID                                             4385    6251    6323    \\\n",
       "Book-Title                                                                   \n",
       "1984                                                   0.0     0.0     0.0   \n",
       "1st to Die: A Novel                                    0.0     0.0     0.0   \n",
       "2nd Chance                                             0.0     0.0     0.0   \n",
       "4 Blondes                                              0.0     0.0     0.0   \n",
       "A Bend in the Road                                     0.0     0.0     0.0   \n",
       "...                                                    ...     ...     ...   \n",
       "Year of Wonders                                        0.0     0.0     0.0   \n",
       "You Belong To Me                                       0.0     0.0     0.0   \n",
       "Zen and the Art of Motorcycle Maintenance: An I...     0.0     0.0     0.0   \n",
       "Zoya                                                   0.0     0.0     0.0   \n",
       "\\O\\\" Is for Outlaw\"                                    0.0     0.0     0.0   \n",
       "\n",
       "User-ID                                             6543    ...  271705  \\\n",
       "Book-Title                                                  ...           \n",
       "1984                                                   0.0  ...    10.0   \n",
       "1st to Die: A Novel                                    9.0  ...     0.0   \n",
       "2nd Chance                                             0.0  ...     0.0   \n",
       "4 Blondes                                              0.0  ...     0.0   \n",
       "A Bend in the Road                                     0.0  ...     0.0   \n",
       "...                                                    ...  ...     ...   \n",
       "Year of Wonders                                        0.0  ...     0.0   \n",
       "You Belong To Me                                       0.0  ...     0.0   \n",
       "Zen and the Art of Motorcycle Maintenance: An I...     0.0  ...     0.0   \n",
       "Zoya                                                   0.0  ...     0.0   \n",
       "\\O\\\" Is for Outlaw\"                                    0.0  ...     0.0   \n",
       "\n",
       "User-ID                                             273979  274004  274061  \\\n",
       "Book-Title                                                                   \n",
       "1984                                                   0.0     0.0     0.0   \n",
       "1st to Die: A Novel                                    0.0     0.0     0.0   \n",
       "2nd Chance                                             0.0     0.0     0.0   \n",
       "4 Blondes                                              0.0     0.0     0.0   \n",
       "A Bend in the Road                                     0.0     0.0     0.0   \n",
       "...                                                    ...     ...     ...   \n",
       "Year of Wonders                                        9.0     0.0     0.0   \n",
       "You Belong To Me                                       0.0     0.0     0.0   \n",
       "Zen and the Art of Motorcycle Maintenance: An I...     0.0     0.0     0.0   \n",
       "Zoya                                                   0.0     0.0     0.0   \n",
       "\\O\\\" Is for Outlaw\"                                    0.0     0.0     0.0   \n",
       "\n",
       "User-ID                                             274301  274308  275970  \\\n",
       "Book-Title                                                                   \n",
       "1984                                                   0.0     0.0     0.0   \n",
       "1st to Die: A Novel                                    0.0     0.0     0.0   \n",
       "2nd Chance                                             0.0     0.0     0.0   \n",
       "4 Blondes                                              0.0     0.0     0.0   \n",
       "A Bend in the Road                                     0.0     0.0     0.0   \n",
       "...                                                    ...     ...     ...   \n",
       "Year of Wonders                                        0.0     0.0     0.0   \n",
       "You Belong To Me                                       0.0     0.0     0.0   \n",
       "Zen and the Art of Motorcycle Maintenance: An I...     0.0     0.0     0.0   \n",
       "Zoya                                                   0.0     0.0     0.0   \n",
       "\\O\\\" Is for Outlaw\"                                    8.0     0.0     0.0   \n",
       "\n",
       "User-ID                                             277427  277639  278418  \n",
       "Book-Title                                                                  \n",
       "1984                                                   0.0     0.0     0.0  \n",
       "1st to Die: A Novel                                    0.0     0.0     0.0  \n",
       "2nd Chance                                             0.0     0.0     0.0  \n",
       "4 Blondes                                              0.0     0.0     0.0  \n",
       "A Bend in the Road                                     0.0     0.0     0.0  \n",
       "...                                                    ...     ...     ...  \n",
       "Year of Wonders                                        0.0     0.0     0.0  \n",
       "You Belong To Me                                       0.0     0.0     0.0  \n",
       "Zen and the Art of Motorcycle Maintenance: An I...     0.0     0.0     0.0  \n",
       "Zoya                                                   0.0     0.0     0.0  \n",
       "\\O\\\" Is for Outlaw\"                                    0.0     0.0     0.0  \n",
       "\n",
       "[706 rows x 810 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt = final_ratings.pivot_table(index='Book-Title',columns='User-ID'\n",
    "                          ,values='Book-Rating')\n",
    "pt.fillna(0,inplace=True)\n",
    "pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_score = cosine_similarity(pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(book_name):\n",
    "    index = np.where(pt.index==book_name)[0][0]\n",
    "    similar_books = sorted(list(enumerate(similarity_score[index])),key=lambda x:x[1], reverse=True)[1:6]\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for i in similar_books:\n",
    "        item = []\n",
    "        temp_df = books[books['Book-Title'] == pt.index[i[0]]]\n",
    "        item.extend(list(temp_df.drop_duplicates('Book-Title')['Book-Title'].values))\n",
    "        item.extend(list(temp_df.drop_duplicates('Book-Title')['Book-Author'].values))\n",
    " \n",
    "        data.append(item)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The Rescue', 'Nicholas Sparks'],\n",
       " ['Nights in Rodanthe', 'Nicholas Sparks'],\n",
       " ['The Notebook', 'Nicholas Sparks'],\n",
       " ['Granny Dan', 'DANIELLE STEEL'],\n",
       " ['A Bend in the Road', 'Nicholas Sparks']]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend(\"A Walk to Remember\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-surprise\n",
      "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.9/site-packages (from scikit-surprise) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/a788/.local/lib/python3.9/site-packages (from scikit-surprise) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/a788/.local/lib/python3.9/site-packages (from scikit-surprise) (1.13.0)\n",
      "Building wheels for collected packages: scikit-surprise\n",
      "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp39-cp39-macosx_10_9_x86_64.whl size=511115 sha256=7b22a61ff430dea8a42530e0b6ac26a2d479704d89f7c20c638bb6ca973bf056\n",
      "  Stored in directory: /Users/a788/Library/Caches/pip/wheels/42/41/d3/a56ae864ad22cc6583ec9312be43fbc611c87e53dc49aac953\n",
      "Successfully built scikit-surprise\n",
      "Installing collected packages: scikit-surprise\n",
      "Successfully installed scikit-surprise-1.1.4\n"
     ]
    }
   ],
   "source": [
    "# Install Surprise library\n",
    "!pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "# Define the rating scale\n",
    "reader = Reader(rating_scale=(0, 10))\n",
    "\n",
    "# Load the data into Surprise's dataset format\n",
    "data = Dataset.load_from_df(complete_df[['User-ID', 'Book-Title', 'Book-Rating']], reader)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_set, test_set = train_test_split(data, test_size=0.20, random_state=42)\n",
    "\n",
    "# Define the SVD algorithm\n",
    "model = SVD()\n",
    "\n",
    "# Train the algorithm on the training set\n",
    "model.fit(train_set)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.test(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.5175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.517453882848987"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10: 0.8624\n",
      "Recall@10: 0.5069\n",
      "F1 Score@10: 0.4540\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from surprise import accuracy\n",
    "\n",
    "def precision_recall_at_k(predictions, k=10, threshold=4.0):\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
    "\n",
    "    return precisions, recalls\n",
    "\n",
    "def calculate_f1(precisions, recalls):\n",
    "    f1_scores = {}\n",
    "    for uid in precisions:\n",
    "        if precisions[uid] + recalls[uid] > 0:\n",
    "            f1_scores[uid] = 2 * (precisions[uid] * recalls[uid]) / (precisions[uid] + recalls[uid])\n",
    "        else:\n",
    "            f1_scores[uid] = 0\n",
    "    return f1_scores\n",
    "\n",
    "precisions, recalls = precision_recall_at_k(predictions, k=10, threshold=4.0)\n",
    "f1_scores = calculate_f1(precisions, recalls)\n",
    "\n",
    "avg_precision = sum(precisions.values()) / len(precisions)\n",
    "avg_recall = sum(recalls.values()) / len(recalls)\n",
    "avg_f1 = sum(f1_scores.values()) / len(f1_scores)\n",
    "\n",
    "print(f'Precision@10: {avg_precision:.4f}')\n",
    "print(f'Recall@10: {avg_recall:.4f}')\n",
    "print(f'F1 Score@10: {avg_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@10: 0.5446\n"
     ]
    }
   ],
   "source": [
    "def mean_average_precision(predictions, k=10):\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "    \n",
    "    average_precisions = []\n",
    "\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "        n_rel_and_rec_k = sum(1 for (est, true_r) in user_ratings[:k] if true_r >= 4.0)\n",
    "        precisions_at_k = [sum(1 for (est, true_r) in user_ratings[:i+1] if true_r >= 4.0) / (i + 1) for i in range(k)]\n",
    "        average_precision = sum(precisions_at_k[:n_rel_and_rec_k]) / min(k, n_rel_and_rec_k) if n_rel_and_rec_k != 0 else 0\n",
    "        average_precisions.append(average_precision)\n",
    "\n",
    "    return sum(average_precisions) / len(average_precisions)\n",
    "\n",
    "# Example usage\n",
    "map_score = mean_average_precision(predictions, k=10)\n",
    "print(f'MAP@10: {map_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up data structures for GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make graph\n",
    "src = torch.tensor(ratings['New-User-ID'].values)\n",
    "dst = torch.tensor(ratings['Book-ID'].values)\n",
    "\n",
    "edges = {\n",
    "    ('user', 'rating', 'book'): (src, dst)\n",
    "}\n",
    "\n",
    "g = dgl.heterograph(edges, num_nodes_dict={'user': num_users, 'book': num_books})\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight the edges by ratings\n",
    "rating_data = ratings['Book-Rating'].values\n",
    "ratings_tensor = torch.tensor(rating_data, dtype=torch.float32)\n",
    "g.edges['rating'].data['rating'] = ratings_tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add age to user feature\n",
    "ages = users_clean['Age'].values\n",
    "ages_tensor = torch.tensor(ages, dtype=torch.float32)\n",
    "g.nodes['user'].data['age'] = ages_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract the country from the location by obtaining the expression after the last comma in e.g. nyc, new york, usa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_clean['Country'] = users_clean['Location'].str.rsplit(',', n=1).str[-1].str.strip()\n",
    "country_counts = users_clean['Country'].value_counts(normalize=True) \n",
    "\n",
    "# We see that less frequent locations do not always contain country names, so we remove values of locations representing less than 1%\n",
    "rare_countries = country_counts[country_counts < 0.01].index\n",
    "users_clean.loc[users_clean['Country'].isin(rare_countries), 'Country'] = np.nan\n",
    "\n",
    "country_ids = {country: idx for idx, country in enumerate(users_clean['Country'].unique())}  # map country to a unique integer\n",
    "users_clean['CountryId'] = users_clean['Country'].map(country_ids)\n",
    "countries = users_clean['CountryId'].values\n",
    "countries_tensor = torch.tensor(countries, dtype=torch.float32)\n",
    "g.nodes['user'].data['country'] = countries_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g.nodes['user'])\n",
    "print(g.nodes['book'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic graph info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g)  # Prints the basic info of the graph, such as number of nodes and edges per type\n",
    "\n",
    "# Print number of nodes for each type\n",
    "print(\"Number of users:\", g.number_of_nodes('user'))\n",
    "print(\"Number of books:\", g.number_of_nodes('book'))\n",
    "\n",
    "# Print number of edges\n",
    "print(\"Number of ratings:\", g.number_of_edges('rating'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node and Edge feature inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print user node features\n",
    "print(\"User features:\", g.nodes['user'].data.keys())\n",
    "\n",
    "# Print book node features, if any\n",
    "print(\"Book features:\", g.nodes['book'].data.keys())\n",
    "\n",
    "# Print edge features\n",
    "print(\"Edge features:\", g.edges['rating'].data.keys())\n",
    "\n",
    "# Example to print specific feature details:\n",
    "print(\"Sample user ages:\", g.nodes['user'].data['age'][:5])  # prints first 5 user ages\n",
    "print(\"Sample ratings:\", g.edges['rating'].data['rating'][:5])  # prints first 5 ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminate isolated nodes if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compact_g = dgl.compact_graphs(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create synthetic features for book based on degree of the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_in_degrees = g.in_degrees(etype=('user', 'rating', 'book')).float().unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.nodes['book'].data['in_degree'] = book_in_degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = g\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "node_types = g.ntypes\n",
    "edge_types = g.etypes\n",
    "print(\"Node types:\", node_types)\n",
    "print(\"Edge types:\", edge_types)\n",
    "print('Number of rating edges:', g.number_of_edges('rating'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the GNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl.nn import SAGEConv\n",
    "\n",
    "class GNNEncoder(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_channels):\n",
    "        super(GNNEncoder, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_feats, hidden_channels, 'mean')\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels, 'mean')\n",
    "\n",
    "    def forward(self, g, features):\n",
    "        h = self.conv1(g, features)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        print(f\"Encoder output shape: {h.shape}\")  # Debugging output\n",
    "        return h\n",
    "\n",
    "class BookEmbedding(nn.Module):\n",
    "    def __init__(self, num_books, embedding_dim):\n",
    "        super(BookEmbedding, self).__init__()\n",
    "        self.book_embedding = nn.Embedding(num_books, embedding_dim)\n",
    "\n",
    "    def forward(self, book_ids):\n",
    "        embeddings = self.book_embedding(book_ids)\n",
    "        print(f\"Book embedding shape: {embeddings.shape}\") \n",
    "        return embeddings\n",
    "\n",
    "class EdgeDecoder(nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(EdgeDecoder, self).__init__()\n",
    "        self.lin1 = torch.nn.Linear(2 * hidden_channels, hidden_channels)\n",
    "        self.lin2 = torch.nn.Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, g, h_user, h_book):\n",
    "        with g.local_scope():\n",
    "            g.nodes['user'].data['h'] = h_user\n",
    "            g.nodes['book'].data['h'] = h_book\n",
    "            \n",
    "            # Ensure edge function is only applied where it should be\n",
    "            if 'rating' in g.etypes:\n",
    "                g.apply_edges(func=lambda edges: {\n",
    "                    'score': self.lin2(F.relu(self.lin1(torch.cat([edges.src['h'], edges.dst['h']], dim=1))))\n",
    "                }, etype='rating')\n",
    "            return g.edata.get('score', torch.tensor([]))  # Handle case where no edges exist\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_books, in_feats_user, hidden_channels):\n",
    "        super(Model, self).__init__()\n",
    "        self.user_encoder = GNNEncoder(in_feats_user, hidden_channels)\n",
    "        self.book_embedding = BookEmbedding(num_books, hidden_channels)\n",
    "        self.decoder = EdgeDecoder(hidden_channels)\n",
    "\n",
    "    def forward(self, g, user_features, book_ids):\n",
    "        h_user = self.user_encoder(g, user_features)\n",
    "        h_book = self.book_embedding(book_ids)\n",
    "        return self.decoder(g, h_user, h_book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split graph for training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_graph(g, proportion=0.8):\n",
    "    # Split edges randomly for training and validation\n",
    "    num_edges = g.number_of_edges('rating')\n",
    "    all_edges = np.arange(num_edges)\n",
    "    np.random.shuffle(all_edges)\n",
    "    \n",
    "    train_size = int(num_edges * proportion)\n",
    "    train_edges = all_edges[:train_size]\n",
    "    val_edges = all_edges[train_size:]\n",
    "    \n",
    "    # Create subgraphs based on the edges\n",
    "    g_train = dgl.edge_subgraph(g, train_edges, relabel_nodes=False)\n",
    "    g_val = dgl.edge_subgraph(g, val_edges, relabel_nodes=False)\n",
    "    \n",
    "    return g_train, g_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_train, g_val = split_graph(g, proportion=0.8)\n",
    "\n",
    "age_tensor_val = g_val.nodes['user'].data['age'].unsqueeze(1)\n",
    "country_tensor_val = g_val.nodes['user'].data['country'].unsqueeze(1)\n",
    "user_features_val = torch.cat([age_tensor_val, country_tensor_val], dim=1)\n",
    "\n",
    "# Assuming book_ids are just the indices of the books, adjust if necessary\n",
    "book_ids_train = torch.arange(g_train.number_of_nodes('book'))\n",
    "book_ids_val = torch.arange(g_val.number_of_nodes('book'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "`criterion` - MSE loss that calculates the average squared difference between the predicted outputs and the actual target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_ids_train = g_train.nodes['book'].data['orig_id']\n",
    "book_ids_val = g_val.nodes['book'].data['orig_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, g, user_features, book_ids, ratings, optimizer, criterion):\n",
    "    model.train()  # Set the model to training mode\n",
    "    optimizer.zero_grad()  # Clear gradients before each backward pass\n",
    "\n",
    "    # Move data to the correct device\n",
    "    g = g.to(device)\n",
    "    user_features = user_features.to(device)\n",
    "    book_ids = book_ids.to(device)\n",
    "    ratings = ratings.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    predictions = model(g, user_features, book_ids)\n",
    "    loss = criterion(predictions, ratings)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, g, user_features, book_ids, ratings, criterion):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient calculation for evaluation, which saves memory and computations\n",
    "        g = g.to(device)\n",
    "        user_features = user_features.to(device)\n",
    "        book_ids = book_ids.to(device)\n",
    "        ratings = ratings.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        predictions = model(g, user_features, book_ids)\n",
    "        loss = criterion(predictions, ratings)\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, g_train, user_features_train, book_ids_train, ratings_train, optimizer, criterion)\n",
    "    val_loss = validate(model, g_val, user_features_val, book_ids_val, ratings_val, criterion)\n",
    "    print(f'Epoch {epoch + 1}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, g, user_features, book_features, labels, criterion):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(g, user_features, book_features)\n",
    "        loss = criterion(outputs, labels)\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation loss\n",
    "validation_loss = evaluate(model, g_val, user_features_val, book_features_val, ratings_val, criterion)\n",
    "print(f'Validation Loss: {validation_loss}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "8f6377febe87314814c7b7161cea679ad38a9298f17e15a391a898e937fe96e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
