# Recommender_GNN

# Useful Links:
[Valuable Python Library (DGL) to train and test GNN models for recommendation](https://docs.dgl.ai/)

[Example repo](https://github.com/je-dbl/GNN-RecSys)

# Papers to look into:
- [A survey of GNNs for recommender systems](https://arxiv.org/pdf/2109.12843.pdf)
- [Product recommendation system using GNN](https://ceur-ws.org/Vol-3426/paper15.pdf)
- [Graph based product recommendation](https://nhtsai.github.io/graph-rec/)

# Abstract
In this project, we aim to develop a book recommender system employing the graph neural network (GNN) architecture. The GNN algorithm enables the integration of contextual information of users and/or items, and is thus, potentially able to capture more dynamic, complex relationshiops than traditional matrix-filling algorithms. We will use a dataset containing book ratings, with user and item metadata (ID, demographics, etc.) Through the project, we would like to explore whether this state-of-art model can outperform more conventional methods such as collaborative filtering.

# Research Question

Tentative list of RQs:
- How to apply GNN to a recommender system for books?
- How should our node be characterized?
- What would our edge consist of?
- Would the algorithm be more centered around user similarity or item similarity?

# Dataset
List the dataset(s) you want to use, and some ideas on how do you expect to get, manage, process and enrich it/them. Show you've read the docs and are familiar with some examples, and you've a clear idea on what to expect. Discuss data size and format if relevant.

- [Book Recommendation Dataset - Kaggle](https://www.kaggle.com/datasets/arashnic/book-recommendation-dataset?select=classicRec.png)
  - This Data Set is good because it contains language data that we can easily process. We can take inspiration from the codes that have been made, and take it a step further by implementing a GNN architecture.


 
# A tentative list of milestones for the project
Add here a sketch of your planning for the coming weeks. Please mention who does what.

* 1st week: Preprocessing (Jules, Linka)
* 2nd week: Get the model architecture (Barto, Naglis)
* 3rd week: continue previous weeks work and train the model (Barto, Linka, Naglis)
* 4th week: Evaluate the model performance and do the presentation (Jules, Barto, Naglis, Linka)

# Documentation
This can be added as the project unfolds. You should describe, in particular, what your repo contains and how to reproduce your results.
