{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Book Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "from dgl.nn import GraphConv\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276725</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276726</td>\n",
       "      <td>0155061224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276727</td>\n",
       "      <td>0446520802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276729</td>\n",
       "      <td>052165615X</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276729</td>\n",
       "      <td>0521795028</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149775</th>\n",
       "      <td>276704</td>\n",
       "      <td>1563526298</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149776</th>\n",
       "      <td>276706</td>\n",
       "      <td>0679447156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149777</th>\n",
       "      <td>276709</td>\n",
       "      <td>0515107662</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149778</th>\n",
       "      <td>276721</td>\n",
       "      <td>0590442449</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149779</th>\n",
       "      <td>276723</td>\n",
       "      <td>05162443314</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1149780 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         User-ID         ISBN  Book-Rating\n",
       "0         276725   034545104X            0\n",
       "1         276726   0155061224            5\n",
       "2         276727   0446520802            0\n",
       "3         276729   052165615X            3\n",
       "4         276729   0521795028            6\n",
       "...          ...          ...          ...\n",
       "1149775   276704   1563526298            9\n",
       "1149776   276706   0679447156            0\n",
       "1149777   276709   0515107662           10\n",
       "1149778   276721   0590442449           10\n",
       "1149779   276723  05162443314            8\n",
       "\n",
       "[1149780 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv(\"Data/Ratings.csv\")\n",
    "#print(f\"{ratings.dtypes}\\n\")\n",
    "#print(ratings.head())\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     716109\n",
       "8     103736\n",
       "10     78610\n",
       "7      76457\n",
       "9      67541\n",
       "5      50974\n",
       "6      36924\n",
       "4       8904\n",
       "3       5996\n",
       "2       2759\n",
       "1       1770\n",
       "Name: Book-Rating, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings[\"Book-Rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>W. W. Norton &amp;amp; Company</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271355</th>\n",
       "      <td>0440400988</td>\n",
       "      <td>There's a Bat in Bunk Five</td>\n",
       "      <td>Paula Danziger</td>\n",
       "      <td>1988</td>\n",
       "      <td>Random House Childrens Pub (Mm)</td>\n",
       "      <td>http://images.amazon.com/images/P/0440400988.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0440400988.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0440400988.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271356</th>\n",
       "      <td>0525447644</td>\n",
       "      <td>From One to One Hundred</td>\n",
       "      <td>Teri Sloat</td>\n",
       "      <td>1991</td>\n",
       "      <td>Dutton Books</td>\n",
       "      <td>http://images.amazon.com/images/P/0525447644.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0525447644.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0525447644.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271357</th>\n",
       "      <td>006008667X</td>\n",
       "      <td>Lily Dale : The True Story of the Town that Ta...</td>\n",
       "      <td>Christine Wicker</td>\n",
       "      <td>2004</td>\n",
       "      <td>HarperSanFrancisco</td>\n",
       "      <td>http://images.amazon.com/images/P/006008667X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/006008667X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/006008667X.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271358</th>\n",
       "      <td>0192126040</td>\n",
       "      <td>Republic (World's Classics)</td>\n",
       "      <td>Plato</td>\n",
       "      <td>1996</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0192126040.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0192126040.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0192126040.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271359</th>\n",
       "      <td>0767409752</td>\n",
       "      <td>A Guided Tour of Rene Descartes' Meditations o...</td>\n",
       "      <td>Christopher  Biffle</td>\n",
       "      <td>2000</td>\n",
       "      <td>McGraw-Hill Humanities/Social Sciences/Languages</td>\n",
       "      <td>http://images.amazon.com/images/P/0767409752.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0767409752.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0767409752.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>271360 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ISBN                                         Book-Title  \\\n",
       "0       0195153448                                Classical Mythology   \n",
       "1       0002005018                                       Clara Callan   \n",
       "2       0060973129                               Decision in Normandy   \n",
       "3       0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "4       0393045218                             The Mummies of Urumchi   \n",
       "...            ...                                                ...   \n",
       "271355  0440400988                         There's a Bat in Bunk Five   \n",
       "271356  0525447644                            From One to One Hundred   \n",
       "271357  006008667X  Lily Dale : The True Story of the Town that Ta...   \n",
       "271358  0192126040                        Republic (World's Classics)   \n",
       "271359  0767409752  A Guided Tour of Rene Descartes' Meditations o...   \n",
       "\n",
       "                 Book-Author Year-Of-Publication  \\\n",
       "0         Mark P. O. Morford                2002   \n",
       "1       Richard Bruce Wright                2001   \n",
       "2               Carlo D'Este                1991   \n",
       "3           Gina Bari Kolata                1999   \n",
       "4            E. J. W. Barber                1999   \n",
       "...                      ...                 ...   \n",
       "271355        Paula Danziger                1988   \n",
       "271356            Teri Sloat                1991   \n",
       "271357      Christine Wicker                2004   \n",
       "271358                 Plato                1996   \n",
       "271359   Christopher  Biffle                2000   \n",
       "\n",
       "                                               Publisher  \\\n",
       "0                                Oxford University Press   \n",
       "1                                  HarperFlamingo Canada   \n",
       "2                                        HarperPerennial   \n",
       "3                                   Farrar Straus Giroux   \n",
       "4                             W. W. Norton &amp; Company   \n",
       "...                                                  ...   \n",
       "271355                   Random House Childrens Pub (Mm)   \n",
       "271356                                      Dutton Books   \n",
       "271357                                HarperSanFrancisco   \n",
       "271358                           Oxford University Press   \n",
       "271359  McGraw-Hill Humanities/Social Sciences/Languages   \n",
       "\n",
       "                                              Image-URL-S  \\\n",
       "0       http://images.amazon.com/images/P/0195153448.0...   \n",
       "1       http://images.amazon.com/images/P/0002005018.0...   \n",
       "2       http://images.amazon.com/images/P/0060973129.0...   \n",
       "3       http://images.amazon.com/images/P/0374157065.0...   \n",
       "4       http://images.amazon.com/images/P/0393045218.0...   \n",
       "...                                                   ...   \n",
       "271355  http://images.amazon.com/images/P/0440400988.0...   \n",
       "271356  http://images.amazon.com/images/P/0525447644.0...   \n",
       "271357  http://images.amazon.com/images/P/006008667X.0...   \n",
       "271358  http://images.amazon.com/images/P/0192126040.0...   \n",
       "271359  http://images.amazon.com/images/P/0767409752.0...   \n",
       "\n",
       "                                              Image-URL-M  \\\n",
       "0       http://images.amazon.com/images/P/0195153448.0...   \n",
       "1       http://images.amazon.com/images/P/0002005018.0...   \n",
       "2       http://images.amazon.com/images/P/0060973129.0...   \n",
       "3       http://images.amazon.com/images/P/0374157065.0...   \n",
       "4       http://images.amazon.com/images/P/0393045218.0...   \n",
       "...                                                   ...   \n",
       "271355  http://images.amazon.com/images/P/0440400988.0...   \n",
       "271356  http://images.amazon.com/images/P/0525447644.0...   \n",
       "271357  http://images.amazon.com/images/P/006008667X.0...   \n",
       "271358  http://images.amazon.com/images/P/0192126040.0...   \n",
       "271359  http://images.amazon.com/images/P/0767409752.0...   \n",
       "\n",
       "                                              Image-URL-L  \n",
       "0       http://images.amazon.com/images/P/0195153448.0...  \n",
       "1       http://images.amazon.com/images/P/0002005018.0...  \n",
       "2       http://images.amazon.com/images/P/0060973129.0...  \n",
       "3       http://images.amazon.com/images/P/0374157065.0...  \n",
       "4       http://images.amazon.com/images/P/0393045218.0...  \n",
       "...                                                   ...  \n",
       "271355  http://images.amazon.com/images/P/0440400988.0...  \n",
       "271356  http://images.amazon.com/images/P/0525447644.0...  \n",
       "271357  http://images.amazon.com/images/P/006008667X.0...  \n",
       "271358  http://images.amazon.com/images/P/0192126040.0...  \n",
       "271359  http://images.amazon.com/images/P/0767409752.0...  \n",
       "\n",
       "[271360 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books = pd.read_csv(\"Data/Books.csv\", dtype={3: str})\n",
    "#print(f\"Books Data Shape: {books.shape} \\n\")\n",
    "#print(f\"{books.dtypes}\\n\")\n",
    "#print(books.head(3))\n",
    "\n",
    "books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nan-values by column\n",
      "ISBN                   0\n",
      "Book-Title             0\n",
      "Book-Author            1\n",
      "Year-Of-Publication    0\n",
      "Publisher              2\n",
      "Image-URL-S            0\n",
      "Image-URL-M            0\n",
      "Image-URL-L            3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Nan-values by column')\n",
    "print(books.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>nyc, new york, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>stockton, california, usa</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>moscow, yukon territory, russia</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>porto, v.n.gaia, portugal</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>farnborough, hants, united kingdom</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278853</th>\n",
       "      <td>278854</td>\n",
       "      <td>portland, oregon, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278854</th>\n",
       "      <td>278855</td>\n",
       "      <td>tacoma, washington, united kingdom</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278855</th>\n",
       "      <td>278856</td>\n",
       "      <td>brampton, ontario, canada</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278856</th>\n",
       "      <td>278857</td>\n",
       "      <td>knoxville, tennessee, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278857</th>\n",
       "      <td>278858</td>\n",
       "      <td>dublin, n/a, ireland</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>278858 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        User-ID                            Location   Age\n",
       "0             1                  nyc, new york, usa   NaN\n",
       "1             2           stockton, california, usa  18.0\n",
       "2             3     moscow, yukon territory, russia   NaN\n",
       "3             4           porto, v.n.gaia, portugal  17.0\n",
       "4             5  farnborough, hants, united kingdom   NaN\n",
       "...         ...                                 ...   ...\n",
       "278853   278854               portland, oregon, usa   NaN\n",
       "278854   278855  tacoma, washington, united kingdom  50.0\n",
       "278855   278856           brampton, ontario, canada   NaN\n",
       "278856   278857           knoxville, tennessee, usa   NaN\n",
       "278857   278858                dublin, n/a, ireland   NaN\n",
       "\n",
       "[278858 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = pd.read_csv(\"Data/Users.csv\")\n",
    "#print(f\"Users Data Shape: {users.shape} \\n\")\n",
    "#print(f\"{users.dtypes}\\n\")\n",
    "#print(users.head())\n",
    "#print('Nan-values by column')\n",
    "#print(users.isna().sum())\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 105283 unique users, and 340556 unique books in the ratings dataset.\n",
      "There are around 21.0% of books in the graph missing in the books data\n"
     ]
    }
   ],
   "source": [
    "# We will only use users and books present in the ratings dataset \n",
    "lessen_user_ids = {userid: idx for idx, userid in enumerate(ratings['User-ID'].unique())} #renumber IDs to reduce inactive users\n",
    "ratings['New-User-ID'] = ratings['User-ID'].map(lessen_user_ids)\n",
    "user_ids = list(ratings['New-User-ID'].unique())\n",
    "num_users = len(set(user_ids))\n",
    "\n",
    "# Map book identifiers (ISBN) to a unique integer identifier for datatype compatibility of dgl\n",
    "isbn_to_id = {isbn: idx for idx, isbn in enumerate(ratings['ISBN'].unique())}\n",
    "ratings['Book-ID'] = ratings['ISBN'].map(isbn_to_id)\n",
    "book_ids = list(ratings['Book-ID'].unique())\n",
    "num_books = len(set(book_ids))\n",
    "\n",
    "print(f'There are {len(user_ids)} unique users, and {len(book_ids)} unique books in the ratings dataset.')\n",
    " \n",
    "# Remove users and books not included in the ratings dataset\n",
    "books['Book-ID'] = books['ISBN'].map(isbn_to_id)\n",
    "books_clean = books[books['Book-ID'].isin(book_ids)]\n",
    "books_clean_ids = books_clean['Book-ID'].unique()\n",
    "percent_books_missing = round((num_books-len(books_clean_ids))/num_books*100, 0)\n",
    "\n",
    "print(f'There are around {percent_books_missing}% of books in the graph missing in the books data')\n",
    "\n",
    "users['New-User-ID'] = users['User-ID'].map(lessen_user_ids)\n",
    "users_clean = users[users['New-User-ID'].isin(user_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1/5 of the books that have rating information do not have further information on the books dataset. However, as our objective is to investigate a user-based recommender system, this is irrelevant. We are able to embed the age and location data of users. As the age data is sparse, location data will be our main source of information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model \n",
    "\n",
    "The following code is based mainly on [this Kaggle project](https://www.kaggle.com/code/fahadmehfoooz/book-recommendation-system) as our baseline model/way to determine the scoring for recommended systems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>New-User-ID_x</th>\n",
       "      <th>Book-ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "      <th>New-User-ID_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276725</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>tyler, texas, usa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276726</td>\n",
       "      <td>0155061224</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>seattle, washington, usa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276727</td>\n",
       "      <td>0446520802</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>h, new south wales, australia</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276729</td>\n",
       "      <td>052165615X</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>rijeka, n/a, croatia</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276729</td>\n",
       "      <td>0521795028</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>rijeka, n/a, croatia</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149775</th>\n",
       "      <td>276704</td>\n",
       "      <td>1563526298</td>\n",
       "      <td>9</td>\n",
       "      <td>105278</td>\n",
       "      <td>226347</td>\n",
       "      <td>cedar park, texas, usa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105278.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149776</th>\n",
       "      <td>276706</td>\n",
       "      <td>0679447156</td>\n",
       "      <td>0</td>\n",
       "      <td>105279</td>\n",
       "      <td>7295</td>\n",
       "      <td>quebec, quebec, canada</td>\n",
       "      <td>18.0</td>\n",
       "      <td>105279.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149777</th>\n",
       "      <td>276709</td>\n",
       "      <td>0515107662</td>\n",
       "      <td>10</td>\n",
       "      <td>105280</td>\n",
       "      <td>12065</td>\n",
       "      <td>mannington, west virginia, usa</td>\n",
       "      <td>38.0</td>\n",
       "      <td>105280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149778</th>\n",
       "      <td>276721</td>\n",
       "      <td>0590442449</td>\n",
       "      <td>10</td>\n",
       "      <td>105281</td>\n",
       "      <td>78598</td>\n",
       "      <td>providence, rhode island, usa</td>\n",
       "      <td>14.0</td>\n",
       "      <td>105281.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149779</th>\n",
       "      <td>276723</td>\n",
       "      <td>05162443314</td>\n",
       "      <td>8</td>\n",
       "      <td>105282</td>\n",
       "      <td>340555</td>\n",
       "      <td>san antonio, texas, usa</td>\n",
       "      <td>12.0</td>\n",
       "      <td>105282.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1149780 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         User-ID         ISBN  Book-Rating  New-User-ID_x  Book-ID  \\\n",
       "0         276725   034545104X            0              0        0   \n",
       "1         276726   0155061224            5              1        1   \n",
       "2         276727   0446520802            0              2        2   \n",
       "3         276729   052165615X            3              3        3   \n",
       "4         276729   0521795028            6              3        4   \n",
       "...          ...          ...          ...            ...      ...   \n",
       "1149775   276704   1563526298            9         105278   226347   \n",
       "1149776   276706   0679447156            0         105279     7295   \n",
       "1149777   276709   0515107662           10         105280    12065   \n",
       "1149778   276721   0590442449           10         105281    78598   \n",
       "1149779   276723  05162443314            8         105282   340555   \n",
       "\n",
       "                               Location   Age  New-User-ID_y  \n",
       "0                     tyler, texas, usa   NaN            0.0  \n",
       "1              seattle, washington, usa   NaN            1.0  \n",
       "2         h, new south wales, australia  16.0            2.0  \n",
       "3                  rijeka, n/a, croatia  16.0            3.0  \n",
       "4                  rijeka, n/a, croatia  16.0            3.0  \n",
       "...                                 ...   ...            ...  \n",
       "1149775          cedar park, texas, usa   NaN       105278.0  \n",
       "1149776          quebec, quebec, canada  18.0       105279.0  \n",
       "1149777  mannington, west virginia, usa  38.0       105280.0  \n",
       "1149778   providence, rhode island, usa  14.0       105281.0  \n",
       "1149779         san antonio, texas, usa  12.0       105282.0  \n",
       "\n",
       "[1149780 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_rating_df = ratings.merge(users_clean, left_on = 'User-ID', right_on = 'User-ID')\n",
    "user_rating_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_user_rating = books_clean.merge(user_rating_df, left_on = 'ISBN',right_on = 'ISBN')\n",
    "book_user_rating = book_user_rating[['ISBN', 'Book-Title', 'Book-Author', 'User-ID', 'Book-Rating']]\n",
    "book_user_rating.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>unique_id_book</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>11400</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>11676</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>41385</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031131</th>\n",
       "      <td>0440400988</td>\n",
       "      <td>There's a Bat in Bunk Five</td>\n",
       "      <td>Paula Danziger</td>\n",
       "      <td>276463</td>\n",
       "      <td>7</td>\n",
       "      <td>270146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031132</th>\n",
       "      <td>0525447644</td>\n",
       "      <td>From One to One Hundred</td>\n",
       "      <td>Teri Sloat</td>\n",
       "      <td>276579</td>\n",
       "      <td>4</td>\n",
       "      <td>270147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031133</th>\n",
       "      <td>006008667X</td>\n",
       "      <td>Lily Dale : The True Story of the Town that Ta...</td>\n",
       "      <td>Christine Wicker</td>\n",
       "      <td>276680</td>\n",
       "      <td>0</td>\n",
       "      <td>270148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031134</th>\n",
       "      <td>0192126040</td>\n",
       "      <td>Republic (World's Classics)</td>\n",
       "      <td>Plato</td>\n",
       "      <td>276680</td>\n",
       "      <td>0</td>\n",
       "      <td>270149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031135</th>\n",
       "      <td>0767409752</td>\n",
       "      <td>A Guided Tour of Rene Descartes' Meditations o...</td>\n",
       "      <td>Christopher  Biffle</td>\n",
       "      <td>276680</td>\n",
       "      <td>0</td>\n",
       "      <td>270150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1031136 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ISBN                                         Book-Title  \\\n",
       "0        0195153448                                Classical Mythology   \n",
       "1        0002005018                                       Clara Callan   \n",
       "2        0002005018                                       Clara Callan   \n",
       "3        0002005018                                       Clara Callan   \n",
       "4        0002005018                                       Clara Callan   \n",
       "...             ...                                                ...   \n",
       "1031131  0440400988                         There's a Bat in Bunk Five   \n",
       "1031132  0525447644                            From One to One Hundred   \n",
       "1031133  006008667X  Lily Dale : The True Story of the Town that Ta...   \n",
       "1031134  0192126040                        Republic (World's Classics)   \n",
       "1031135  0767409752  A Guided Tour of Rene Descartes' Meditations o...   \n",
       "\n",
       "                  Book-Author  User-ID  Book-Rating  unique_id_book  \n",
       "0          Mark P. O. Morford        2            0               0  \n",
       "1        Richard Bruce Wright        8            5               1  \n",
       "2        Richard Bruce Wright    11400            0               1  \n",
       "3        Richard Bruce Wright    11676            8               1  \n",
       "4        Richard Bruce Wright    41385            0               1  \n",
       "...                       ...      ...          ...             ...  \n",
       "1031131        Paula Danziger   276463            7          270146  \n",
       "1031132            Teri Sloat   276579            4          270147  \n",
       "1031133      Christine Wicker   276680            0          270148  \n",
       "1031134                 Plato   276680            0          270149  \n",
       "1031135   Christopher  Biffle   276680            0          270150  \n",
       "\n",
       "[1031136 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d ={}\n",
    "for i,j in enumerate(book_user_rating.ISBN.unique()):\n",
    "    d[j] =i\n",
    "book_user_rating['unique_id_book'] = book_user_rating['ISBN'].map(d)\n",
    "book_user_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note\n",
    "The matrix could not be generated due to significant level of potential cells generated by the pivot operation, thus, only 25k values are taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_users = book_user_rating['User-ID'].value_counts().head(25000).index\n",
    "top_books = book_user_rating['ISBN'].value_counts().head(25000).index\n",
    "\n",
    "\n",
    "filtered_df = book_user_rating[book_user_rating['User-ID'].isin(top_users) & book_user_rating['ISBN'].isin(top_books)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_books_pivot_matrix_df = filtered_df.pivot(index='User-ID', columns='unique_id_book', values='Book-Rating').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>unique_id_book</th>\n",
       "      <th>1</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>14</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>...</th>\n",
       "      <th>200983</th>\n",
       "      <th>202721</th>\n",
       "      <th>202858</th>\n",
       "      <th>206478</th>\n",
       "      <th>207047</th>\n",
       "      <th>207905</th>\n",
       "      <th>211778</th>\n",
       "      <th>213175</th>\n",
       "      <th>216604</th>\n",
       "      <th>242947</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User-ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278838</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278843</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278849</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278851</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278854</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24028 rows × 24997 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "unique_id_book  1       3       5       14      18      19      20      \\\n",
       "User-ID                                                                  \n",
       "8                  5.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "9                  0.0     0.0     0.0     0.0     0.0     6.0     0.0   \n",
       "14                 0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "17                 0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "44                 0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...                ...     ...     ...     ...     ...     ...     ...   \n",
       "278838             0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "278843             0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "278849             0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "278851             0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "278854             0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "unique_id_book  21      26      27      ...  200983  202721  202858  206478  \\\n",
       "User-ID                                 ...                                   \n",
       "8                  0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0   \n",
       "9                  0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0   \n",
       "14                 0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0   \n",
       "17                 0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0   \n",
       "44                 0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0   \n",
       "...                ...     ...     ...  ...     ...     ...     ...     ...   \n",
       "278838             0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0   \n",
       "278843             0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0   \n",
       "278849             0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0   \n",
       "278851             0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0   \n",
       "278854             0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0   \n",
       "\n",
       "unique_id_book  207047  207905  211778  213175  216604  242947  \n",
       "User-ID                                                         \n",
       "8                  0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "9                  0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "14                 0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "17                 0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "44                 0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "...                ...     ...     ...     ...     ...     ...  \n",
       "278838             0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "278843             0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "278849             0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "278851             0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "278854             0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[24028 rows x 24997 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_books_pivot_matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_books_pivot_matrix_df = users_books_pivot_matrix_df.values\n",
    "users_books_pivot_matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "NUMBER_OF_FACTORS_MF = 15\n",
    "\n",
    "#Performs matrix factorization of the original user item matrix\n",
    "U, sigma, Vt = svds(users_books_pivot_matrix_df, k = NUMBER_OF_FACTORS_MF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 15)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma = np.diag(sigma)\n",
    "sigma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.62992369e-03, -7.96688151e-05,  1.74241255e-03, ...,\n",
       "        -1.29732512e-05, -2.77965402e-04,  1.03031736e-05],\n",
       "       [ 1.75972105e-03,  3.53753414e-04,  2.39309070e-03, ...,\n",
       "        -5.59043184e-05,  2.29810704e-04,  3.55624878e-04],\n",
       "       [-1.10039267e-16, -2.21102829e-17, -4.92502738e-17, ...,\n",
       "        -2.82481351e-18, -1.95597555e-16, -1.57502303e-18],\n",
       "       ...,\n",
       "       [-3.49879326e-05,  5.85305748e-05,  2.29358951e-05, ...,\n",
       "        -2.53933980e-05,  6.28585274e-04,  5.45062455e-05],\n",
       "       [ 5.12240230e-03,  3.37804276e-04,  6.36386495e-03, ...,\n",
       "        -2.77432983e-04, -8.31703348e-04,  2.41251880e-04],\n",
       "       [-2.17779347e-03,  1.13588515e-03, -1.86067297e-03, ...,\n",
       "         2.14495407e-04, -3.06683737e-03, -8.30582340e-04]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt) \n",
    "all_user_predicted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_cosine_similarity(data, book_id, top_n=10):\n",
    "    index = book_id \n",
    "    book_row = data[index, :]\n",
    "    magnitude = np.sqrt(np.einsum('ij, ij -> i', data, data))\n",
    "    similarity = np.dot(book_row, data.T) / (magnitude[index] * magnitude)\n",
    "    sort_indexes = np.argsort(-similarity)\n",
    "    return sort_indexes[:top_n]\n",
    "\n",
    "def similar_books(book_user_rating, book_id, top_indexes):\n",
    "    print('Recommendations for {0}: \\n'.format(\n",
    "    book_user_rating[book_user_rating.unique_id_book == book_id]['Book-Title'].values[0]))\n",
    "    for id in top_indexes + 1:\n",
    "        print(book_user_rating[book_user_rating.unique_id_book == id]['Book-Title'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for A Cold Day for Murder: \n",
      "\n",
      "The White Puma\n",
      "Rules of Prey\n",
      "Where There's Smoke\n",
      "Les llengÃ¼es d'Africa (Biblioteca universal EmpÃºries)\n",
      "The Relationship Cure: A Five-Step Guide for Building Better Connections with Family, Friends, and Lovers\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore', category=RuntimeWarning, message='invalid value encountered in divide')\n",
    "\n",
    "k = 50\n",
    "movie_id = 2002  \n",
    "top_n = 5\n",
    "sliced = Vt.T[:, :k] # representative data\n",
    "\n",
    "top_similarities = top_cosine_similarity(sliced, movie_id, top_n)\n",
    "recommended_books = similar_books(book_user_rating, movie_id, top_similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse(test_set, predictions):\n",
    "    # Ensure indices are set for joining\n",
    "    test_set = test_set.set_index(['User-ID', 'ISBN'])\n",
    "    predictions = predictions.set_index(['User-ID', 'ISBN'])\n",
    "    \n",
    "    # Join the test and prediction dataframes on 'User-ID' and 'ISBN'\n",
    "    combined = test_set.join(predictions, lsuffix='_actual', rsuffix='_pred')\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(combined['Book-Rating_actual'], combined['Book-Rating_pred']))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up data structures for GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make graph\n",
    "src = torch.tensor(ratings['New-User-ID'].values)\n",
    "dst = torch.tensor(ratings['Book-ID'].values)\n",
    "\n",
    "edges = {\n",
    "    ('user', 'rating', 'book'): (src, dst)\n",
    "}\n",
    "\n",
    "g = dgl.heterograph(edges, num_nodes_dict={'user': num_users, 'book': num_books})\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight the edges by ratings\n",
    "rating_data = ratings['Book-Rating'].values\n",
    "ratings_tensor = torch.tensor(rating_data, dtype=torch.float32)\n",
    "g.edges['rating'].data['rating'] = ratings_tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add age to user feature\n",
    "ages = users_clean['Age'].values\n",
    "ages_tensor = torch.tensor(ages, dtype=torch.float32)\n",
    "g.nodes['user'].data['age'] = ages_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract the country from the location by obtaining the expression after the last comma in e.g. nyc, new york, usa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_clean['Country'] = users_clean['Location'].str.rsplit(',', n=1).str[-1].str.strip()\n",
    "country_counts = users_clean['Country'].value_counts(normalize=True) \n",
    "\n",
    "# We see that less frequent locations do not always contain country names, so we remove values of locations representing less than 1%\n",
    "rare_countries = country_counts[country_counts < 0.01].index\n",
    "users_clean.loc[users_clean['Country'].isin(rare_countries), 'Country'] = np.nan\n",
    "\n",
    "country_ids = {country: idx for idx, country in enumerate(users_clean['Country'].unique())}  # map country to a unique integer\n",
    "users_clean['CountryId'] = users_clean['Country'].map(country_ids)\n",
    "countries = users_clean['CountryId'].values\n",
    "countries_tensor = torch.tensor(countries, dtype=torch.float32)\n",
    "g.nodes['user'].data['country'] = countries_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g.nodes['user'])\n",
    "print(g.nodes['book'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic graph info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g)  # Prints the basic info of the graph, such as number of nodes and edges per type\n",
    "\n",
    "# Print number of nodes for each type\n",
    "print(\"Number of users:\", g.number_of_nodes('user'))\n",
    "print(\"Number of books:\", g.number_of_nodes('book'))\n",
    "\n",
    "# Print number of edges\n",
    "print(\"Number of ratings:\", g.number_of_edges('rating'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node and Edge feature inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print user node features\n",
    "print(\"User features:\", g.nodes['user'].data.keys())\n",
    "\n",
    "# Print book node features, if any\n",
    "print(\"Book features:\", g.nodes['book'].data.keys())\n",
    "\n",
    "# Print edge features\n",
    "print(\"Edge features:\", g.edges['rating'].data.keys())\n",
    "\n",
    "# Example to print specific feature details:\n",
    "print(\"Sample user ages:\", g.nodes['user'].data['age'][:5])  # prints first 5 user ages\n",
    "print(\"Sample ratings:\", g.edges['rating'].data['rating'][:5])  # prints first 5 ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminate isolated nodes if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compact_g = dgl.compact_graphs(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create synthetic features for book based on degree of the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_in_degrees = g.in_degrees(etype=('user', 'rating', 'book')).float().unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.nodes['book'].data['in_degree'] = book_in_degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = g\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "node_types = g.ntypes\n",
    "edge_types = g.etypes\n",
    "print(\"Node types:\", node_types)\n",
    "print(\"Edge types:\", edge_types)\n",
    "print('Number of rating edges:', g.number_of_edges('rating'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the GNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl.nn import SAGEConv\n",
    "\n",
    "class GNNEncoder(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_channels):\n",
    "        super(GNNEncoder, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_feats, hidden_channels, 'mean')\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels, 'mean')\n",
    "\n",
    "    def forward(self, g, features):\n",
    "        h = self.conv1(g, features)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        print(f\"Encoder output shape: {h.shape}\")  # Debugging output\n",
    "        return h\n",
    "\n",
    "class BookEmbedding(nn.Module):\n",
    "    def __init__(self, num_books, embedding_dim):\n",
    "        super(BookEmbedding, self).__init__()\n",
    "        self.book_embedding = nn.Embedding(num_books, embedding_dim)\n",
    "\n",
    "    def forward(self, book_ids):\n",
    "        embeddings = self.book_embedding(book_ids)\n",
    "        print(f\"Book embedding shape: {embeddings.shape}\") \n",
    "        return embeddings\n",
    "\n",
    "class EdgeDecoder(nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(EdgeDecoder, self).__init__()\n",
    "        self.lin1 = torch.nn.Linear(2 * hidden_channels, hidden_channels)\n",
    "        self.lin2 = torch.nn.Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, g, h_user, h_book):\n",
    "        with g.local_scope():\n",
    "            g.nodes['user'].data['h'] = h_user\n",
    "            g.nodes['book'].data['h'] = h_book\n",
    "            \n",
    "            # Ensure edge function is only applied where it should be\n",
    "            if 'rating' in g.etypes:\n",
    "                g.apply_edges(func=lambda edges: {\n",
    "                    'score': self.lin2(F.relu(self.lin1(torch.cat([edges.src['h'], edges.dst['h']], dim=1))))\n",
    "                }, etype='rating')\n",
    "            return g.edata.get('score', torch.tensor([]))  # Handle case where no edges exist\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_books, in_feats_user, hidden_channels):\n",
    "        super(Model, self).__init__()\n",
    "        self.user_encoder = GNNEncoder(in_feats_user, hidden_channels)\n",
    "        self.book_embedding = BookEmbedding(num_books, hidden_channels)\n",
    "        self.decoder = EdgeDecoder(hidden_channels)\n",
    "\n",
    "    def forward(self, g, user_features, book_ids):\n",
    "        h_user = self.user_encoder(g, user_features)\n",
    "        h_book = self.book_embedding(book_ids)\n",
    "        return self.decoder(g, h_user, h_book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split graph for training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_graph(g, proportion=0.8):\n",
    "    # Split edges randomly for training and validation\n",
    "    num_edges = g.number_of_edges('rating')\n",
    "    all_edges = np.arange(num_edges)\n",
    "    np.random.shuffle(all_edges)\n",
    "    \n",
    "    train_size = int(num_edges * proportion)\n",
    "    train_edges = all_edges[:train_size]\n",
    "    val_edges = all_edges[train_size:]\n",
    "    \n",
    "    # Create subgraphs based on the edges\n",
    "    g_train = dgl.edge_subgraph(g, train_edges, relabel_nodes=False)\n",
    "    g_val = dgl.edge_subgraph(g, val_edges, relabel_nodes=False)\n",
    "    \n",
    "    return g_train, g_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_train, g_val = split_graph(g, proportion=0.8)\n",
    "\n",
    "age_tensor_val = g_val.nodes['user'].data['age'].unsqueeze(1)\n",
    "country_tensor_val = g_val.nodes['user'].data['country'].unsqueeze(1)\n",
    "user_features_val = torch.cat([age_tensor_val, country_tensor_val], dim=1)\n",
    "\n",
    "# Assuming book_ids are just the indices of the books, adjust if necessary\n",
    "book_ids_train = torch.arange(g_train.number_of_nodes('book'))\n",
    "book_ids_val = torch.arange(g_val.number_of_nodes('book'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "`criterion` - MSE loss that calculates the average squared difference between the predicted outputs and the actual target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_ids_train = g_train.nodes['book'].data['orig_id']\n",
    "book_ids_val = g_val.nodes['book'].data['orig_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, g, user_features, book_ids, ratings, optimizer, criterion):\n",
    "    model.train()  # Set the model to training mode\n",
    "    optimizer.zero_grad()  # Clear gradients before each backward pass\n",
    "\n",
    "    # Move data to the correct device\n",
    "    g = g.to(device)\n",
    "    user_features = user_features.to(device)\n",
    "    book_ids = book_ids.to(device)\n",
    "    ratings = ratings.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    predictions = model(g, user_features, book_ids)\n",
    "    loss = criterion(predictions, ratings)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, g, user_features, book_ids, ratings, criterion):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient calculation for evaluation, which saves memory and computations\n",
    "        g = g.to(device)\n",
    "        user_features = user_features.to(device)\n",
    "        book_ids = book_ids.to(device)\n",
    "        ratings = ratings.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        predictions = model(g, user_features, book_ids)\n",
    "        loss = criterion(predictions, ratings)\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, g_train, user_features_train, book_ids_train, ratings_train, optimizer, criterion)\n",
    "    val_loss = validate(model, g_val, user_features_val, book_ids_val, ratings_val, criterion)\n",
    "    print(f'Epoch {epoch + 1}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, g, user_features, book_features, labels, criterion):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(g, user_features, book_features)\n",
    "        loss = criterion(outputs, labels)\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation loss\n",
    "validation_loss = evaluate(model, g_val, user_features_val, book_features_val, ratings_val, criterion)\n",
    "print(f'Validation Loss: {validation_loss}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "8f6377febe87314814c7b7161cea679ad38a9298f17e15a391a898e937fe96e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
